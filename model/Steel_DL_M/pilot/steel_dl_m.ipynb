{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#상위 폴더 load_data파일 불러오기 위해 경로 추가\n",
    "import sys\n",
    "sys.path.append('../')  # 상위 폴더(main_folder)의 경로를 추가\n",
    "\n",
    "# 데이터 가져오기\n",
    "from load_data import *\n",
    "\n",
    "# 텐서플로\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers as Layer\n",
    "from tensorflow.keras.metrics import Recall, Precision, BinaryAccuracy, CategoricalAccuracy, SparseCategoricalAccuracy\n",
    "\n",
    "# 콜백\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤시드 고정\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1540, 20), (385, 20), (482, 20), (1540,), (385,), (482,), MaxAbsScaler())"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MinMaxScaler - 0, StandardScaler - 1, , MaxAbsScaler - 2, RobustScaler - 3, Normalizer - 4\n",
    "X_train0, X_val0, X_test0, y_train0, y_val0, y_test0, scaler0  = load_data(scaler=0, upsampling=1)\n",
    "X_train1, X_val1, X_test1, y_train1, y_val1, y_test1, scaler1  = load_data(scaler=1, upsampling=1)\n",
    "X_train2, X_val2, X_test2, y_train2, y_val2, y_test2, scaler2  = load_data(scaler=2, upsampling=1)\n",
    "X_train3, X_val3, X_test3, y_train3, y_val3, y_test3, scaler3  = load_data(scaler=3, upsampling=1)\n",
    "X_train4, X_val4, X_test4, y_train4, y_val4, y_test4, scaler4  = load_data(scaler=4, upsampling=1)\n",
    "\n",
    "X_train1.shape, X_val1.shape, X_test2.shape, y_train2.shape, y_val2.shape, y_test2.shape, scaler2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimingCallback(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        print(\"Starting training\")\n",
    "        self.starttime = timer()\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        print(\"End of training, took {} seconds\".format(timer()-self.starttime))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 10 == 0:\n",
    "          print(\"Epoch is {} and {} seconds passed\".format(epoch, timer()-self.starttime))\n",
    "\n",
    "\n",
    "def get_model(drop_rate = 0.1,check_path = 'model2.h5', epochs = 1000, batch_size=1024, validation_split=0.1):\n",
    "  model = Sequential()\n",
    "  model.add(Layer.Dense(12, activation = 'relu'))\n",
    "  model.add(Layer.Dropout(0.1))\n",
    "\n",
    "  model.add(Layer.Dense(4, activation = 'relu'))\n",
    "  model.add(Layer.Dropout(0.1))\n",
    "\n",
    "\n",
    "  model.add(Layer.Dense(6, activation = 'softmax'))\n",
    "\n",
    "  metrics = [\n",
    "      SparseCategoricalAccuracy(name = 'accuracy') # Accuracy를 사용 안 하는 이유는 Accuracy가 이상하세 나왔기 때문.\n",
    "  ]\n",
    "\n",
    "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "                 loss=\"sparse_categorical_crossentropy\",\n",
    "                 metrics=metrics)\n",
    "\n",
    "  callback = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"loss\",min_delta = 0.001, patience=100),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=check_path, save_weights_only=True, monitor='loss', mode='min', save_best_only=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.2, patience=100, min_lr=0.01),\n",
    "    TimingCallback()\n",
    "]\n",
    "\n",
    "  history = model.fit(x=X_train0, y=y_train0, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=True,\n",
    "                      validation_split=validation_split)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_path = 'model.h5'\n",
    "\n",
    "callback = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"loss\",min_delta = 0.001, patience=100),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=check_path, save_weights_only=True, monitor='loss', mode='min', save_best_only=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.2, patience=100, min_lr=0.01),\n",
    "    TimingCallback()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 1.8151 - accuracy: 0.1205 - val_loss: 1.7904 - val_accuracy: 0.1688\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.7894 - accuracy: 0.2121 - val_loss: 1.7959 - val_accuracy: 0.1104\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.7877 - accuracy: 0.1991 - val_loss: 1.7825 - val_accuracy: 0.1948\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.7682 - accuracy: 0.2417 - val_loss: 1.7452 - val_accuracy: 0.2208\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.7318 - accuracy: 0.2554 - val_loss: 1.7213 - val_accuracy: 0.2078\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.7154 - accuracy: 0.2179 - val_loss: 1.7008 - val_accuracy: 0.2013\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.7035 - accuracy: 0.2439 - val_loss: 1.6830 - val_accuracy: 0.3117\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6680 - accuracy: 0.3139 - val_loss: 1.6743 - val_accuracy: 0.4091\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6503 - accuracy: 0.4048 - val_loss: 1.6580 - val_accuracy: 0.3701\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6259 - accuracy: 0.4055 - val_loss: 1.6405 - val_accuracy: 0.3831\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5946 - accuracy: 0.4372 - val_loss: 1.6245 - val_accuracy: 0.3896\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5713 - accuracy: 0.4250 - val_loss: 1.5946 - val_accuracy: 0.4156\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.5445 - accuracy: 0.4430 - val_loss: 1.5647 - val_accuracy: 0.4286\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5122 - accuracy: 0.4589 - val_loss: 1.5451 - val_accuracy: 0.4286\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.4887 - accuracy: 0.4654 - val_loss: 1.5256 - val_accuracy: 0.4416\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.4561 - accuracy: 0.4690 - val_loss: 1.5000 - val_accuracy: 0.4481\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.4561 - accuracy: 0.4531 - val_loss: 1.4722 - val_accuracy: 0.4545\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.4235 - accuracy: 0.4654 - val_loss: 1.4493 - val_accuracy: 0.4740\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.4102 - accuracy: 0.4755 - val_loss: 1.4257 - val_accuracy: 0.4805\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.3948 - accuracy: 0.4675 - val_loss: 1.4017 - val_accuracy: 0.4675\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.3463 - accuracy: 0.4949 - val_loss: 1.3795 - val_accuracy: 0.4740\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.3556 - accuracy: 0.4747 - val_loss: 1.3608 - val_accuracy: 0.4675\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.3219 - accuracy: 0.4892 - val_loss: 1.3385 - val_accuracy: 0.4675\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.2797 - accuracy: 0.5108 - val_loss: 1.3108 - val_accuracy: 0.4740\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.2785 - accuracy: 0.4978 - val_loss: 1.2876 - val_accuracy: 0.4935\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.2738 - accuracy: 0.5014 - val_loss: 1.2681 - val_accuracy: 0.5000\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.2508 - accuracy: 0.4892 - val_loss: 1.2466 - val_accuracy: 0.5000\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.2297 - accuracy: 0.5072 - val_loss: 1.2284 - val_accuracy: 0.4740\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.2292 - accuracy: 0.5101 - val_loss: 1.2166 - val_accuracy: 0.4805\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.2220 - accuracy: 0.5029 - val_loss: 1.1983 - val_accuracy: 0.4935\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.1885 - accuracy: 0.5123 - val_loss: 1.1722 - val_accuracy: 0.6429\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.1957 - accuracy: 0.5808 - val_loss: 1.1568 - val_accuracy: 0.6818\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.1677 - accuracy: 0.6017 - val_loss: 1.1436 - val_accuracy: 0.6818\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.1869 - accuracy: 0.5945 - val_loss: 1.1254 - val_accuracy: 0.6883\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.1881 - accuracy: 0.5916 - val_loss: 1.1072 - val_accuracy: 0.6883\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.1633 - accuracy: 0.6032 - val_loss: 1.0993 - val_accuracy: 0.6883\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.1465 - accuracy: 0.5938 - val_loss: 1.0966 - val_accuracy: 0.6818\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.1304 - accuracy: 0.6039 - val_loss: 1.0849 - val_accuracy: 0.6818\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.1497 - accuracy: 0.6025 - val_loss: 1.0649 - val_accuracy: 0.6688\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.1518 - accuracy: 0.5815 - val_loss: 1.0507 - val_accuracy: 0.6818\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.1133 - accuracy: 0.6198 - val_loss: 1.0484 - val_accuracy: 0.6883\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.1064 - accuracy: 0.6183 - val_loss: 1.0396 - val_accuracy: 0.6948\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.0934 - accuracy: 0.6241 - val_loss: 1.0254 - val_accuracy: 0.6818\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.0926 - accuracy: 0.6270 - val_loss: 1.0167 - val_accuracy: 0.6818\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.1019 - accuracy: 0.6089 - val_loss: 1.0130 - val_accuracy: 0.6883\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.0994 - accuracy: 0.6154 - val_loss: 1.0043 - val_accuracy: 0.6818\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.0783 - accuracy: 0.6205 - val_loss: 0.9961 - val_accuracy: 0.6753\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.0784 - accuracy: 0.6111 - val_loss: 0.9882 - val_accuracy: 0.6688\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.0732 - accuracy: 0.6147 - val_loss: 0.9792 - val_accuracy: 0.6883\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.0676 - accuracy: 0.6299 - val_loss: 0.9751 - val_accuracy: 0.6883\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.0748 - accuracy: 0.6147 - val_loss: 0.9736 - val_accuracy: 0.6883\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.0743 - accuracy: 0.6212 - val_loss: 0.9728 - val_accuracy: 0.6883\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.0596 - accuracy: 0.6270 - val_loss: 0.9592 - val_accuracy: 0.6948\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.0649 - accuracy: 0.6349 - val_loss: 0.9487 - val_accuracy: 0.6883\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.0438 - accuracy: 0.6299 - val_loss: 0.9427 - val_accuracy: 0.6883\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.0685 - accuracy: 0.6089 - val_loss: 0.9477 - val_accuracy: 0.6753\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.0287 - accuracy: 0.6342 - val_loss: 0.9459 - val_accuracy: 0.6883\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.0327 - accuracy: 0.6342 - val_loss: 0.9353 - val_accuracy: 0.7013\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.0390 - accuracy: 0.6284 - val_loss: 0.9220 - val_accuracy: 0.6948\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.0349 - accuracy: 0.6284 - val_loss: 0.9167 - val_accuracy: 0.6883\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.0484 - accuracy: 0.6270 - val_loss: 0.9185 - val_accuracy: 0.6948\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.0220 - accuracy: 0.6501 - val_loss: 0.9231 - val_accuracy: 0.7143\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.0435 - accuracy: 0.6234 - val_loss: 0.9208 - val_accuracy: 0.7273\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.0266 - accuracy: 0.6255 - val_loss: 0.9097 - val_accuracy: 0.7208\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.0197 - accuracy: 0.6277 - val_loss: 0.9050 - val_accuracy: 0.7143\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.0296 - accuracy: 0.6255 - val_loss: 0.9029 - val_accuracy: 0.7013\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.0450 - accuracy: 0.6255 - val_loss: 0.9059 - val_accuracy: 0.7143\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.0019 - accuracy: 0.6407 - val_loss: 0.9023 - val_accuracy: 0.7403\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9984 - accuracy: 0.6378 - val_loss: 0.8866 - val_accuracy: 0.7273\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.0114 - accuracy: 0.6385 - val_loss: 0.8775 - val_accuracy: 0.7013\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.0215 - accuracy: 0.6328 - val_loss: 0.8732 - val_accuracy: 0.7338\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9986 - accuracy: 0.6349 - val_loss: 0.8805 - val_accuracy: 0.7662\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9968 - accuracy: 0.6443 - val_loss: 0.8823 - val_accuracy: 0.7532\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.0097 - accuracy: 0.6299 - val_loss: 0.8721 - val_accuracy: 0.7078\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9752 - accuracy: 0.6450 - val_loss: 0.8639 - val_accuracy: 0.7273\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.9856 - accuracy: 0.6356 - val_loss: 0.8610 - val_accuracy: 0.7273\n",
      "Epoch 77/1000\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.9720 - accuracy: 0.6378 - val_loss: 0.8593 - val_accuracy: 0.7338\n",
      "Epoch 78/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.9801 - accuracy: 0.6494 - val_loss: 0.8617 - val_accuracy: 0.7338\n",
      "Epoch 79/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.0024 - accuracy: 0.6328 - val_loss: 0.8606 - val_accuracy: 0.7597\n",
      "Epoch 80/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9703 - accuracy: 0.6508 - val_loss: 0.8539 - val_accuracy: 0.7273\n",
      "Epoch 81/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.9790 - accuracy: 0.6429 - val_loss: 0.8487 - val_accuracy: 0.7338\n",
      "Epoch 82/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.9817 - accuracy: 0.6421 - val_loss: 0.8483 - val_accuracy: 0.7273\n",
      "Epoch 83/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9648 - accuracy: 0.6551 - val_loss: 0.8429 - val_accuracy: 0.7273\n",
      "Epoch 84/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.9914 - accuracy: 0.6356 - val_loss: 0.8377 - val_accuracy: 0.7403\n",
      "Epoch 85/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9651 - accuracy: 0.6450 - val_loss: 0.8355 - val_accuracy: 0.7403\n",
      "Epoch 86/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.0034 - accuracy: 0.6407 - val_loss: 0.8334 - val_accuracy: 0.7403\n",
      "Epoch 87/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9734 - accuracy: 0.6472 - val_loss: 0.8379 - val_accuracy: 0.7597\n",
      "Epoch 88/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9837 - accuracy: 0.6371 - val_loss: 0.8372 - val_accuracy: 0.7597\n",
      "Epoch 89/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.9599 - accuracy: 0.6530 - val_loss: 0.8299 - val_accuracy: 0.7532\n",
      "Epoch 90/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.9559 - accuracy: 0.6573 - val_loss: 0.8245 - val_accuracy: 0.7273\n",
      "Epoch 91/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9464 - accuracy: 0.6494 - val_loss: 0.8205 - val_accuracy: 0.7792\n",
      "Epoch 92/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9464 - accuracy: 0.6609 - val_loss: 0.8274 - val_accuracy: 0.7857\n",
      "Epoch 93/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9816 - accuracy: 0.6450 - val_loss: 0.8271 - val_accuracy: 0.7792\n",
      "Epoch 94/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.9382 - accuracy: 0.6652 - val_loss: 0.8194 - val_accuracy: 0.7727\n",
      "Epoch 95/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.9443 - accuracy: 0.6508 - val_loss: 0.8065 - val_accuracy: 0.7597\n",
      "Epoch 96/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9220 - accuracy: 0.6638 - val_loss: 0.8001 - val_accuracy: 0.7662\n",
      "Epoch 97/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9372 - accuracy: 0.6566 - val_loss: 0.7952 - val_accuracy: 0.7597\n",
      "Epoch 98/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9701 - accuracy: 0.6450 - val_loss: 0.8038 - val_accuracy: 0.8052\n",
      "Epoch 99/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9485 - accuracy: 0.6659 - val_loss: 0.8145 - val_accuracy: 0.7987\n",
      "Epoch 100/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9668 - accuracy: 0.6515 - val_loss: 0.8040 - val_accuracy: 0.7922\n",
      "Epoch 101/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.9404 - accuracy: 0.6580 - val_loss: 0.7968 - val_accuracy: 0.7403\n",
      "Epoch 102/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.9505 - accuracy: 0.6609 - val_loss: 0.7941 - val_accuracy: 0.7403\n",
      "Epoch 103/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9450 - accuracy: 0.6486 - val_loss: 0.7971 - val_accuracy: 0.7597\n",
      "Epoch 104/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9274 - accuracy: 0.6681 - val_loss: 0.7965 - val_accuracy: 0.7857\n",
      "Epoch 105/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.9280 - accuracy: 0.6681 - val_loss: 0.7941 - val_accuracy: 0.7792\n",
      "Epoch 106/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.9514 - accuracy: 0.6392 - val_loss: 0.7872 - val_accuracy: 0.7857\n",
      "Epoch 107/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.9688 - accuracy: 0.6342 - val_loss: 0.7863 - val_accuracy: 0.7857\n",
      "Epoch 108/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9404 - accuracy: 0.6537 - val_loss: 0.7852 - val_accuracy: 0.7792\n",
      "Epoch 109/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9174 - accuracy: 0.6667 - val_loss: 0.7857 - val_accuracy: 0.7597\n",
      "Epoch 110/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9285 - accuracy: 0.6515 - val_loss: 0.7876 - val_accuracy: 0.7662\n",
      "Epoch 111/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9655 - accuracy: 0.6356 - val_loss: 0.7849 - val_accuracy: 0.7922\n",
      "Epoch 112/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.9391 - accuracy: 0.6515 - val_loss: 0.7808 - val_accuracy: 0.7857\n",
      "Epoch 113/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.9391 - accuracy: 0.6457 - val_loss: 0.7745 - val_accuracy: 0.7727\n",
      "Epoch 114/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.9099 - accuracy: 0.6652 - val_loss: 0.7806 - val_accuracy: 0.7662\n",
      "Epoch 115/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.9131 - accuracy: 0.6717 - val_loss: 0.7844 - val_accuracy: 0.7727\n",
      "Epoch 116/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.9259 - accuracy: 0.6558 - val_loss: 0.7879 - val_accuracy: 0.7792\n",
      "Epoch 117/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9208 - accuracy: 0.6645 - val_loss: 0.7785 - val_accuracy: 0.7792\n",
      "Epoch 118/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8989 - accuracy: 0.6638 - val_loss: 0.7696 - val_accuracy: 0.7727\n",
      "Epoch 119/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9271 - accuracy: 0.6587 - val_loss: 0.7619 - val_accuracy: 0.7792\n",
      "Epoch 120/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9022 - accuracy: 0.6681 - val_loss: 0.7612 - val_accuracy: 0.7857\n",
      "Epoch 121/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9271 - accuracy: 0.6573 - val_loss: 0.7672 - val_accuracy: 0.7792\n",
      "Epoch 122/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9073 - accuracy: 0.6551 - val_loss: 0.7800 - val_accuracy: 0.7662\n",
      "Epoch 123/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.9126 - accuracy: 0.6515 - val_loss: 0.7770 - val_accuracy: 0.7597\n",
      "Epoch 124/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.9202 - accuracy: 0.6566 - val_loss: 0.7592 - val_accuracy: 0.7857\n",
      "Epoch 125/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9230 - accuracy: 0.6465 - val_loss: 0.7503 - val_accuracy: 0.7857\n",
      "Epoch 126/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8943 - accuracy: 0.6717 - val_loss: 0.7506 - val_accuracy: 0.7922\n",
      "Epoch 127/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.8963 - accuracy: 0.6544 - val_loss: 0.7574 - val_accuracy: 0.7857\n",
      "Epoch 128/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9066 - accuracy: 0.6652 - val_loss: 0.7572 - val_accuracy: 0.7792\n",
      "Epoch 129/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9170 - accuracy: 0.6645 - val_loss: 0.7569 - val_accuracy: 0.7987\n",
      "Epoch 130/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9254 - accuracy: 0.6544 - val_loss: 0.7586 - val_accuracy: 0.8117\n",
      "Epoch 131/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.8869 - accuracy: 0.6667 - val_loss: 0.7492 - val_accuracy: 0.7987\n",
      "Epoch 132/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8907 - accuracy: 0.6768 - val_loss: 0.7450 - val_accuracy: 0.7922\n",
      "Epoch 133/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8985 - accuracy: 0.6674 - val_loss: 0.7476 - val_accuracy: 0.7727\n",
      "Epoch 134/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8900 - accuracy: 0.6638 - val_loss: 0.7538 - val_accuracy: 0.7857\n",
      "Epoch 135/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9126 - accuracy: 0.6486 - val_loss: 0.7610 - val_accuracy: 0.7922\n",
      "Epoch 136/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9147 - accuracy: 0.6530 - val_loss: 0.7669 - val_accuracy: 0.7987\n",
      "Epoch 137/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.8727 - accuracy: 0.6833 - val_loss: 0.7572 - val_accuracy: 0.7987\n",
      "Epoch 138/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8750 - accuracy: 0.6797 - val_loss: 0.7439 - val_accuracy: 0.7857\n",
      "Epoch 139/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.9190 - accuracy: 0.6472 - val_loss: 0.7397 - val_accuracy: 0.7727\n",
      "Epoch 140/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.8674 - accuracy: 0.6645 - val_loss: 0.7391 - val_accuracy: 0.7727\n",
      "Epoch 141/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8807 - accuracy: 0.6732 - val_loss: 0.7363 - val_accuracy: 0.7792\n",
      "Epoch 142/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8780 - accuracy: 0.6732 - val_loss: 0.7431 - val_accuracy: 0.7792\n",
      "Epoch 143/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8741 - accuracy: 0.6753 - val_loss: 0.7461 - val_accuracy: 0.7792\n",
      "Epoch 144/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8823 - accuracy: 0.6753 - val_loss: 0.7452 - val_accuracy: 0.7662\n",
      "Epoch 145/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8702 - accuracy: 0.6753 - val_loss: 0.7371 - val_accuracy: 0.7792\n",
      "Epoch 146/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.8876 - accuracy: 0.6688 - val_loss: 0.7325 - val_accuracy: 0.7727\n",
      "Epoch 147/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.8632 - accuracy: 0.6912 - val_loss: 0.7343 - val_accuracy: 0.7727\n",
      "Epoch 148/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8763 - accuracy: 0.6804 - val_loss: 0.7377 - val_accuracy: 0.7727\n",
      "Epoch 149/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8919 - accuracy: 0.6703 - val_loss: 0.7361 - val_accuracy: 0.7727\n",
      "Epoch 150/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8483 - accuracy: 0.6962 - val_loss: 0.7305 - val_accuracy: 0.7727\n",
      "Epoch 151/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.8661 - accuracy: 0.6883 - val_loss: 0.7260 - val_accuracy: 0.7857\n",
      "Epoch 152/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8657 - accuracy: 0.7027 - val_loss: 0.7247 - val_accuracy: 0.7857\n",
      "Epoch 153/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8634 - accuracy: 0.7013 - val_loss: 0.7249 - val_accuracy: 0.7857\n",
      "Epoch 154/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.8831 - accuracy: 0.6804 - val_loss: 0.7250 - val_accuracy: 0.7857\n",
      "Epoch 155/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8605 - accuracy: 0.6840 - val_loss: 0.7227 - val_accuracy: 0.7792\n",
      "Epoch 156/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.8822 - accuracy: 0.6710 - val_loss: 0.7183 - val_accuracy: 0.7987\n",
      "Epoch 157/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8698 - accuracy: 0.6768 - val_loss: 0.7188 - val_accuracy: 0.7857\n",
      "Epoch 158/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8178 - accuracy: 0.7071 - val_loss: 0.7181 - val_accuracy: 0.7857\n",
      "Epoch 159/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8403 - accuracy: 0.7006 - val_loss: 0.7177 - val_accuracy: 0.7857\n",
      "Epoch 160/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.8434 - accuracy: 0.6941 - val_loss: 0.7193 - val_accuracy: 0.7792\n",
      "Epoch 161/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.8323 - accuracy: 0.6948 - val_loss: 0.7148 - val_accuracy: 0.7727\n",
      "Epoch 162/1000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.8253 - accuracy: 0.6955 - val_loss: 0.7075 - val_accuracy: 0.7857\n",
      "Epoch 163/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.8747 - accuracy: 0.6746 - val_loss: 0.7102 - val_accuracy: 0.7857\n",
      "Epoch 164/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.8435 - accuracy: 0.6941 - val_loss: 0.7067 - val_accuracy: 0.7857\n",
      "Epoch 165/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8430 - accuracy: 0.6912 - val_loss: 0.7052 - val_accuracy: 0.7792\n",
      "Epoch 166/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8397 - accuracy: 0.6926 - val_loss: 0.7055 - val_accuracy: 0.7922\n",
      "Epoch 167/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8263 - accuracy: 0.6941 - val_loss: 0.7084 - val_accuracy: 0.7922\n",
      "Epoch 168/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.8421 - accuracy: 0.6926 - val_loss: 0.7048 - val_accuracy: 0.7987\n",
      "Epoch 169/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.8448 - accuracy: 0.6977 - val_loss: 0.7017 - val_accuracy: 0.7792\n",
      "Epoch 170/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.8301 - accuracy: 0.6955 - val_loss: 0.6987 - val_accuracy: 0.7792\n",
      "Epoch 171/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.8401 - accuracy: 0.6905 - val_loss: 0.7028 - val_accuracy: 0.7857\n",
      "Epoch 172/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8633 - accuracy: 0.6782 - val_loss: 0.7077 - val_accuracy: 0.7922\n",
      "Epoch 173/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.8302 - accuracy: 0.6948 - val_loss: 0.7041 - val_accuracy: 0.7922\n",
      "Epoch 174/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8296 - accuracy: 0.6912 - val_loss: 0.6931 - val_accuracy: 0.7922\n",
      "Epoch 175/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.8162 - accuracy: 0.7063 - val_loss: 0.6862 - val_accuracy: 0.7922\n",
      "Epoch 176/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.8226 - accuracy: 0.7078 - val_loss: 0.6840 - val_accuracy: 0.7922\n",
      "Epoch 177/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.8278 - accuracy: 0.6984 - val_loss: 0.6855 - val_accuracy: 0.7922\n",
      "Epoch 178/1000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.8478 - accuracy: 0.6948 - val_loss: 0.6845 - val_accuracy: 0.7987\n",
      "Epoch 179/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.8196 - accuracy: 0.7035 - val_loss: 0.6821 - val_accuracy: 0.8117\n",
      "Epoch 180/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.8149 - accuracy: 0.7063 - val_loss: 0.6791 - val_accuracy: 0.8052\n",
      "Epoch 181/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8091 - accuracy: 0.7143 - val_loss: 0.6817 - val_accuracy: 0.8052\n",
      "Epoch 182/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8264 - accuracy: 0.7092 - val_loss: 0.6814 - val_accuracy: 0.7987\n",
      "Epoch 183/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.8104 - accuracy: 0.7020 - val_loss: 0.6832 - val_accuracy: 0.7922\n",
      "Epoch 184/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.7893 - accuracy: 0.7208 - val_loss: 0.6815 - val_accuracy: 0.8052\n",
      "Epoch 185/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.8059 - accuracy: 0.7136 - val_loss: 0.6822 - val_accuracy: 0.8052\n",
      "Epoch 186/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8205 - accuracy: 0.7020 - val_loss: 0.6789 - val_accuracy: 0.7987\n",
      "Epoch 187/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.8242 - accuracy: 0.7056 - val_loss: 0.6828 - val_accuracy: 0.7922\n",
      "Epoch 188/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.7977 - accuracy: 0.7078 - val_loss: 0.6798 - val_accuracy: 0.8052\n",
      "Epoch 189/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7825 - accuracy: 0.7208 - val_loss: 0.6789 - val_accuracy: 0.7987\n",
      "Epoch 190/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.7851 - accuracy: 0.7201 - val_loss: 0.6815 - val_accuracy: 0.7987\n",
      "Epoch 191/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.7837 - accuracy: 0.7280 - val_loss: 0.6868 - val_accuracy: 0.7922\n",
      "Epoch 192/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7781 - accuracy: 0.7179 - val_loss: 0.6775 - val_accuracy: 0.7987\n",
      "Epoch 193/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.7872 - accuracy: 0.7172 - val_loss: 0.6689 - val_accuracy: 0.7987\n",
      "Epoch 194/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.7932 - accuracy: 0.7222 - val_loss: 0.6679 - val_accuracy: 0.7987\n",
      "Epoch 195/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.7896 - accuracy: 0.7193 - val_loss: 0.6674 - val_accuracy: 0.7987\n",
      "Epoch 196/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7690 - accuracy: 0.7258 - val_loss: 0.6583 - val_accuracy: 0.8117\n",
      "Epoch 197/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.8156 - accuracy: 0.7222 - val_loss: 0.6543 - val_accuracy: 0.8117\n",
      "Epoch 198/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.8088 - accuracy: 0.7186 - val_loss: 0.6543 - val_accuracy: 0.8117\n",
      "Epoch 199/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.8011 - accuracy: 0.7208 - val_loss: 0.6630 - val_accuracy: 0.7922\n",
      "Epoch 200/1000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.7974 - accuracy: 0.7251 - val_loss: 0.6634 - val_accuracy: 0.8052\n",
      "Epoch 201/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7852 - accuracy: 0.7229 - val_loss: 0.6650 - val_accuracy: 0.7987\n",
      "Epoch 202/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7912 - accuracy: 0.7244 - val_loss: 0.6637 - val_accuracy: 0.8052\n",
      "Epoch 203/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.7862 - accuracy: 0.7222 - val_loss: 0.6581 - val_accuracy: 0.8052\n",
      "Epoch 204/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7844 - accuracy: 0.7302 - val_loss: 0.6581 - val_accuracy: 0.7987\n",
      "Epoch 205/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7756 - accuracy: 0.7287 - val_loss: 0.6586 - val_accuracy: 0.7987\n",
      "Epoch 206/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7560 - accuracy: 0.7316 - val_loss: 0.6535 - val_accuracy: 0.8117\n",
      "Epoch 207/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.7765 - accuracy: 0.7258 - val_loss: 0.6485 - val_accuracy: 0.8117\n",
      "Epoch 208/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7838 - accuracy: 0.7229 - val_loss: 0.6460 - val_accuracy: 0.8052\n",
      "Epoch 209/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8006 - accuracy: 0.7150 - val_loss: 0.6448 - val_accuracy: 0.7987\n",
      "Epoch 210/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7759 - accuracy: 0.7352 - val_loss: 0.6527 - val_accuracy: 0.7922\n",
      "Epoch 211/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8186 - accuracy: 0.7179 - val_loss: 0.6487 - val_accuracy: 0.7987\n",
      "Epoch 212/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7802 - accuracy: 0.7302 - val_loss: 0.6421 - val_accuracy: 0.8117\n",
      "Epoch 213/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7602 - accuracy: 0.7424 - val_loss: 0.6462 - val_accuracy: 0.8182\n",
      "Epoch 214/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.7912 - accuracy: 0.7258 - val_loss: 0.6414 - val_accuracy: 0.8182\n",
      "Epoch 215/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7684 - accuracy: 0.7287 - val_loss: 0.6389 - val_accuracy: 0.8247\n",
      "Epoch 216/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.7845 - accuracy: 0.7258 - val_loss: 0.6420 - val_accuracy: 0.8182\n",
      "Epoch 217/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7632 - accuracy: 0.7338 - val_loss: 0.6374 - val_accuracy: 0.8182\n",
      "Epoch 218/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7631 - accuracy: 0.7244 - val_loss: 0.6320 - val_accuracy: 0.8182\n",
      "Epoch 219/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7686 - accuracy: 0.7316 - val_loss: 0.6322 - val_accuracy: 0.8117\n",
      "Epoch 220/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7433 - accuracy: 0.7460 - val_loss: 0.6335 - val_accuracy: 0.8117\n",
      "Epoch 221/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7626 - accuracy: 0.7359 - val_loss: 0.6359 - val_accuracy: 0.8312\n",
      "Epoch 222/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7545 - accuracy: 0.7431 - val_loss: 0.6346 - val_accuracy: 0.8182\n",
      "Epoch 223/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.7617 - accuracy: 0.7352 - val_loss: 0.6254 - val_accuracy: 0.8247\n",
      "Epoch 224/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7599 - accuracy: 0.7309 - val_loss: 0.6193 - val_accuracy: 0.8312\n",
      "Epoch 225/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.7567 - accuracy: 0.7410 - val_loss: 0.6097 - val_accuracy: 0.8377\n",
      "Epoch 226/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7611 - accuracy: 0.7338 - val_loss: 0.6069 - val_accuracy: 0.8377\n",
      "Epoch 227/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7645 - accuracy: 0.7424 - val_loss: 0.6082 - val_accuracy: 0.8442\n",
      "Epoch 228/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.7535 - accuracy: 0.7496 - val_loss: 0.6074 - val_accuracy: 0.8442\n",
      "Epoch 229/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.7659 - accuracy: 0.7316 - val_loss: 0.6012 - val_accuracy: 0.8506\n",
      "Epoch 230/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7402 - accuracy: 0.7496 - val_loss: 0.5892 - val_accuracy: 0.8571\n",
      "Epoch 231/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.7332 - accuracy: 0.7641 - val_loss: 0.5736 - val_accuracy: 0.8636\n",
      "Epoch 232/1000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.7409 - accuracy: 0.7475 - val_loss: 0.5632 - val_accuracy: 0.8636\n",
      "Epoch 233/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.7471 - accuracy: 0.7439 - val_loss: 0.5651 - val_accuracy: 0.8571\n",
      "Epoch 234/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.7039 - accuracy: 0.7619 - val_loss: 0.5615 - val_accuracy: 0.8571\n",
      "Epoch 235/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.7260 - accuracy: 0.7583 - val_loss: 0.5604 - val_accuracy: 0.8571\n",
      "Epoch 236/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.7127 - accuracy: 0.7691 - val_loss: 0.5546 - val_accuracy: 0.8636\n",
      "Epoch 237/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.7116 - accuracy: 0.7554 - val_loss: 0.5496 - val_accuracy: 0.8571\n",
      "Epoch 238/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7208 - accuracy: 0.7612 - val_loss: 0.5442 - val_accuracy: 0.8701\n",
      "Epoch 239/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7161 - accuracy: 0.7569 - val_loss: 0.5388 - val_accuracy: 0.8571\n",
      "Epoch 240/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6896 - accuracy: 0.7583 - val_loss: 0.5410 - val_accuracy: 0.8636\n",
      "Epoch 241/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6882 - accuracy: 0.7597 - val_loss: 0.5434 - val_accuracy: 0.8636\n",
      "Epoch 242/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.7326 - accuracy: 0.7453 - val_loss: 0.5306 - val_accuracy: 0.8701\n",
      "Epoch 243/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7160 - accuracy: 0.7540 - val_loss: 0.5225 - val_accuracy: 0.8636\n",
      "Epoch 244/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6898 - accuracy: 0.7597 - val_loss: 0.5272 - val_accuracy: 0.8636\n",
      "Epoch 245/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6878 - accuracy: 0.7590 - val_loss: 0.5274 - val_accuracy: 0.8571\n",
      "Epoch 246/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6746 - accuracy: 0.7655 - val_loss: 0.5149 - val_accuracy: 0.8701\n",
      "Epoch 247/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6716 - accuracy: 0.7583 - val_loss: 0.5122 - val_accuracy: 0.8701\n",
      "Epoch 248/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6836 - accuracy: 0.7713 - val_loss: 0.5095 - val_accuracy: 0.8701\n",
      "Epoch 249/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6950 - accuracy: 0.7561 - val_loss: 0.4999 - val_accuracy: 0.8701\n",
      "Epoch 250/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6742 - accuracy: 0.7662 - val_loss: 0.4964 - val_accuracy: 0.8766\n",
      "Epoch 251/1000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.6716 - accuracy: 0.7662 - val_loss: 0.4990 - val_accuracy: 0.8831\n",
      "Epoch 252/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6968 - accuracy: 0.7670 - val_loss: 0.5032 - val_accuracy: 0.8766\n",
      "Epoch 253/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6959 - accuracy: 0.7749 - val_loss: 0.4926 - val_accuracy: 0.8766\n",
      "Epoch 254/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6732 - accuracy: 0.7814 - val_loss: 0.4825 - val_accuracy: 0.8831\n",
      "Epoch 255/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6546 - accuracy: 0.7799 - val_loss: 0.4795 - val_accuracy: 0.8831\n",
      "Epoch 256/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6725 - accuracy: 0.7713 - val_loss: 0.4842 - val_accuracy: 0.8701\n",
      "Epoch 257/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6493 - accuracy: 0.7835 - val_loss: 0.4882 - val_accuracy: 0.8571\n",
      "Epoch 258/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6436 - accuracy: 0.7778 - val_loss: 0.4772 - val_accuracy: 0.8701\n",
      "Epoch 259/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.6467 - accuracy: 0.7872 - val_loss: 0.4635 - val_accuracy: 0.8766\n",
      "Epoch 260/1000\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6863 - accuracy: 0.7792 - val_loss: 0.4699 - val_accuracy: 0.8766\n",
      "Epoch 261/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6325 - accuracy: 0.7785 - val_loss: 0.4767 - val_accuracy: 0.8701\n",
      "Epoch 262/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6523 - accuracy: 0.7821 - val_loss: 0.4748 - val_accuracy: 0.8571\n",
      "Epoch 263/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6490 - accuracy: 0.7807 - val_loss: 0.4527 - val_accuracy: 0.8636\n",
      "Epoch 264/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6766 - accuracy: 0.7742 - val_loss: 0.4442 - val_accuracy: 0.8896\n",
      "Epoch 265/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6675 - accuracy: 0.7771 - val_loss: 0.4593 - val_accuracy: 0.8701\n",
      "Epoch 266/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6337 - accuracy: 0.7879 - val_loss: 0.4758 - val_accuracy: 0.8571\n",
      "Epoch 267/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6585 - accuracy: 0.7734 - val_loss: 0.4684 - val_accuracy: 0.8701\n",
      "Epoch 268/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6344 - accuracy: 0.7937 - val_loss: 0.4462 - val_accuracy: 0.8896\n",
      "Epoch 269/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6429 - accuracy: 0.7792 - val_loss: 0.4316 - val_accuracy: 0.8961\n",
      "Epoch 270/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6344 - accuracy: 0.7763 - val_loss: 0.4315 - val_accuracy: 0.8896\n",
      "Epoch 271/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6291 - accuracy: 0.7799 - val_loss: 0.4408 - val_accuracy: 0.8766\n",
      "Epoch 272/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6464 - accuracy: 0.7778 - val_loss: 0.4471 - val_accuracy: 0.8766\n",
      "Epoch 273/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6611 - accuracy: 0.7684 - val_loss: 0.4455 - val_accuracy: 0.8831\n",
      "Epoch 274/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6216 - accuracy: 0.7915 - val_loss: 0.4327 - val_accuracy: 0.8896\n",
      "Epoch 275/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6525 - accuracy: 0.7908 - val_loss: 0.4292 - val_accuracy: 0.8896\n",
      "Epoch 276/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6422 - accuracy: 0.7720 - val_loss: 0.4344 - val_accuracy: 0.8831\n",
      "Epoch 277/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6681 - accuracy: 0.7763 - val_loss: 0.4334 - val_accuracy: 0.8831\n",
      "Epoch 278/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6474 - accuracy: 0.7749 - val_loss: 0.4325 - val_accuracy: 0.8896\n",
      "Epoch 279/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6499 - accuracy: 0.7742 - val_loss: 0.4255 - val_accuracy: 0.8831\n",
      "Epoch 280/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6608 - accuracy: 0.7597 - val_loss: 0.4249 - val_accuracy: 0.8831\n",
      "Epoch 281/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6012 - accuracy: 0.7951 - val_loss: 0.4343 - val_accuracy: 0.8831\n",
      "Epoch 282/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6118 - accuracy: 0.7908 - val_loss: 0.4341 - val_accuracy: 0.8831\n",
      "Epoch 283/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6340 - accuracy: 0.7843 - val_loss: 0.4324 - val_accuracy: 0.8766\n",
      "Epoch 284/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6313 - accuracy: 0.7908 - val_loss: 0.4339 - val_accuracy: 0.8896\n",
      "Epoch 285/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.6249 - accuracy: 0.7857 - val_loss: 0.4320 - val_accuracy: 0.8831\n",
      "Epoch 286/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.6384 - accuracy: 0.7835 - val_loss: 0.4308 - val_accuracy: 0.8896\n",
      "Epoch 287/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6391 - accuracy: 0.7734 - val_loss: 0.4185 - val_accuracy: 0.8896\n",
      "Epoch 288/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6128 - accuracy: 0.7893 - val_loss: 0.4109 - val_accuracy: 0.9026\n",
      "Epoch 289/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6218 - accuracy: 0.7785 - val_loss: 0.4129 - val_accuracy: 0.8961\n",
      "Epoch 290/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6024 - accuracy: 0.7958 - val_loss: 0.4236 - val_accuracy: 0.8831\n",
      "Epoch 291/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5906 - accuracy: 0.7965 - val_loss: 0.4224 - val_accuracy: 0.8831\n",
      "Epoch 292/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5957 - accuracy: 0.7908 - val_loss: 0.4137 - val_accuracy: 0.8896\n",
      "Epoch 293/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6497 - accuracy: 0.7720 - val_loss: 0.4319 - val_accuracy: 0.8506\n",
      "Epoch 294/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6170 - accuracy: 0.7864 - val_loss: 0.4278 - val_accuracy: 0.8766\n",
      "Epoch 295/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6146 - accuracy: 0.7807 - val_loss: 0.4344 - val_accuracy: 0.8831\n",
      "Epoch 296/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6531 - accuracy: 0.7648 - val_loss: 0.4172 - val_accuracy: 0.8831\n",
      "Epoch 297/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6256 - accuracy: 0.7756 - val_loss: 0.4054 - val_accuracy: 0.8961\n",
      "Epoch 298/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6158 - accuracy: 0.7951 - val_loss: 0.4112 - val_accuracy: 0.8896\n",
      "Epoch 299/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6144 - accuracy: 0.7864 - val_loss: 0.4110 - val_accuracy: 0.8896\n",
      "Epoch 300/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5967 - accuracy: 0.7973 - val_loss: 0.4098 - val_accuracy: 0.8831\n",
      "Epoch 301/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5987 - accuracy: 0.7900 - val_loss: 0.4114 - val_accuracy: 0.8896\n",
      "Epoch 302/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6140 - accuracy: 0.7792 - val_loss: 0.4054 - val_accuracy: 0.8961\n",
      "Epoch 303/1000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5851 - accuracy: 0.7944 - val_loss: 0.4152 - val_accuracy: 0.8831\n",
      "Epoch 304/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6092 - accuracy: 0.7814 - val_loss: 0.4115 - val_accuracy: 0.8831\n",
      "Epoch 305/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6152 - accuracy: 0.7900 - val_loss: 0.4006 - val_accuracy: 0.8831\n",
      "Epoch 306/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5968 - accuracy: 0.7937 - val_loss: 0.3926 - val_accuracy: 0.8961\n",
      "Epoch 307/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6202 - accuracy: 0.7879 - val_loss: 0.4034 - val_accuracy: 0.8896\n",
      "Epoch 308/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5823 - accuracy: 0.7965 - val_loss: 0.4121 - val_accuracy: 0.8831\n",
      "Epoch 309/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6111 - accuracy: 0.7778 - val_loss: 0.4095 - val_accuracy: 0.8831\n",
      "Epoch 310/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6075 - accuracy: 0.7792 - val_loss: 0.4091 - val_accuracy: 0.8831\n",
      "Epoch 311/1000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5838 - accuracy: 0.7900 - val_loss: 0.4033 - val_accuracy: 0.8896\n",
      "Epoch 312/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6003 - accuracy: 0.7850 - val_loss: 0.4027 - val_accuracy: 0.8831\n",
      "Epoch 313/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5931 - accuracy: 0.7944 - val_loss: 0.4019 - val_accuracy: 0.8831\n",
      "Epoch 314/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5792 - accuracy: 0.7973 - val_loss: 0.3907 - val_accuracy: 0.8831\n",
      "Epoch 315/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6149 - accuracy: 0.7785 - val_loss: 0.3811 - val_accuracy: 0.8896\n",
      "Epoch 316/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5971 - accuracy: 0.7994 - val_loss: 0.3876 - val_accuracy: 0.8961\n",
      "Epoch 317/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6027 - accuracy: 0.7973 - val_loss: 0.4017 - val_accuracy: 0.8766\n",
      "Epoch 318/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5801 - accuracy: 0.7937 - val_loss: 0.4068 - val_accuracy: 0.8766\n",
      "Epoch 319/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5873 - accuracy: 0.7922 - val_loss: 0.4137 - val_accuracy: 0.8636\n",
      "Epoch 320/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5952 - accuracy: 0.7821 - val_loss: 0.4186 - val_accuracy: 0.8766\n",
      "Epoch 321/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5907 - accuracy: 0.7951 - val_loss: 0.4150 - val_accuracy: 0.8831\n",
      "Epoch 322/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5863 - accuracy: 0.7980 - val_loss: 0.4100 - val_accuracy: 0.8831\n",
      "Epoch 323/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6134 - accuracy: 0.7821 - val_loss: 0.4113 - val_accuracy: 0.8701\n",
      "Epoch 324/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6186 - accuracy: 0.7857 - val_loss: 0.4063 - val_accuracy: 0.8766\n",
      "Epoch 325/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5906 - accuracy: 0.7973 - val_loss: 0.4115 - val_accuracy: 0.8766\n",
      "Epoch 326/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5935 - accuracy: 0.7922 - val_loss: 0.4140 - val_accuracy: 0.8831\n",
      "Epoch 327/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6064 - accuracy: 0.7850 - val_loss: 0.4108 - val_accuracy: 0.8766\n",
      "Epoch 328/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6001 - accuracy: 0.7951 - val_loss: 0.4103 - val_accuracy: 0.8766\n",
      "Epoch 329/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5994 - accuracy: 0.7980 - val_loss: 0.4173 - val_accuracy: 0.8701\n",
      "Epoch 330/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6042 - accuracy: 0.7734 - val_loss: 0.4069 - val_accuracy: 0.8766\n",
      "Epoch 331/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5815 - accuracy: 0.7893 - val_loss: 0.3859 - val_accuracy: 0.8896\n",
      "Epoch 332/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5930 - accuracy: 0.7937 - val_loss: 0.3719 - val_accuracy: 0.9026\n",
      "Epoch 333/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5889 - accuracy: 0.7922 - val_loss: 0.3733 - val_accuracy: 0.8896\n",
      "Epoch 334/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5911 - accuracy: 0.7900 - val_loss: 0.3872 - val_accuracy: 0.8896\n",
      "Epoch 335/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6135 - accuracy: 0.7799 - val_loss: 0.4133 - val_accuracy: 0.8766\n",
      "Epoch 336/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5833 - accuracy: 0.7922 - val_loss: 0.4109 - val_accuracy: 0.8831\n",
      "Epoch 337/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5845 - accuracy: 0.7908 - val_loss: 0.3935 - val_accuracy: 0.8961\n",
      "Epoch 338/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5867 - accuracy: 0.7944 - val_loss: 0.3873 - val_accuracy: 0.8961\n",
      "Epoch 339/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6161 - accuracy: 0.7850 - val_loss: 0.4027 - val_accuracy: 0.8896\n",
      "Epoch 340/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5797 - accuracy: 0.7994 - val_loss: 0.4087 - val_accuracy: 0.8766\n",
      "Epoch 341/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5767 - accuracy: 0.7944 - val_loss: 0.3915 - val_accuracy: 0.8896\n",
      "Epoch 342/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5924 - accuracy: 0.7785 - val_loss: 0.3824 - val_accuracy: 0.8896\n",
      "Epoch 343/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6010 - accuracy: 0.7828 - val_loss: 0.3866 - val_accuracy: 0.8831\n",
      "Epoch 344/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5672 - accuracy: 0.7994 - val_loss: 0.3985 - val_accuracy: 0.8961\n",
      "Epoch 345/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5927 - accuracy: 0.7857 - val_loss: 0.3996 - val_accuracy: 0.8961\n",
      "Epoch 346/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6084 - accuracy: 0.7872 - val_loss: 0.3838 - val_accuracy: 0.8961\n",
      "Epoch 347/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5958 - accuracy: 0.7886 - val_loss: 0.3959 - val_accuracy: 0.8831\n",
      "Epoch 348/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5773 - accuracy: 0.8001 - val_loss: 0.4194 - val_accuracy: 0.8571\n",
      "Epoch 349/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6063 - accuracy: 0.7879 - val_loss: 0.4045 - val_accuracy: 0.8766\n",
      "Epoch 350/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5900 - accuracy: 0.7835 - val_loss: 0.3798 - val_accuracy: 0.8961\n",
      "Epoch 351/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5874 - accuracy: 0.7915 - val_loss: 0.3788 - val_accuracy: 0.8896\n",
      "Epoch 352/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5938 - accuracy: 0.7864 - val_loss: 0.3956 - val_accuracy: 0.8896\n",
      "Epoch 353/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5564 - accuracy: 0.7994 - val_loss: 0.3972 - val_accuracy: 0.8896\n",
      "Epoch 354/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5745 - accuracy: 0.8016 - val_loss: 0.3862 - val_accuracy: 0.8961\n",
      "Epoch 355/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5827 - accuracy: 0.7922 - val_loss: 0.3810 - val_accuracy: 0.8961\n",
      "Epoch 356/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5854 - accuracy: 0.7857 - val_loss: 0.3869 - val_accuracy: 0.8831\n",
      "Epoch 357/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5620 - accuracy: 0.7973 - val_loss: 0.3950 - val_accuracy: 0.8831\n",
      "Epoch 358/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6008 - accuracy: 0.7951 - val_loss: 0.3959 - val_accuracy: 0.8961\n",
      "Epoch 359/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5943 - accuracy: 0.7937 - val_loss: 0.3823 - val_accuracy: 0.8896\n",
      "Epoch 360/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5756 - accuracy: 0.7922 - val_loss: 0.3760 - val_accuracy: 0.8896\n",
      "Epoch 361/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5636 - accuracy: 0.7915 - val_loss: 0.3843 - val_accuracy: 0.8961\n",
      "Epoch 362/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5701 - accuracy: 0.7958 - val_loss: 0.3942 - val_accuracy: 0.8831\n",
      "Epoch 363/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5734 - accuracy: 0.7944 - val_loss: 0.4021 - val_accuracy: 0.8831\n",
      "Epoch 364/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5823 - accuracy: 0.8016 - val_loss: 0.3785 - val_accuracy: 0.8896\n",
      "Epoch 365/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5574 - accuracy: 0.7864 - val_loss: 0.3716 - val_accuracy: 0.9026\n",
      "Epoch 366/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5934 - accuracy: 0.7872 - val_loss: 0.3795 - val_accuracy: 0.9026\n",
      "Epoch 367/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5727 - accuracy: 0.7980 - val_loss: 0.4129 - val_accuracy: 0.8831\n",
      "Epoch 368/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5632 - accuracy: 0.8038 - val_loss: 0.4014 - val_accuracy: 0.8896\n",
      "Epoch 369/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5706 - accuracy: 0.7872 - val_loss: 0.3736 - val_accuracy: 0.8961\n",
      "Epoch 370/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5738 - accuracy: 0.7879 - val_loss: 0.3583 - val_accuracy: 0.9026\n",
      "Epoch 371/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5726 - accuracy: 0.7944 - val_loss: 0.3606 - val_accuracy: 0.9026\n",
      "Epoch 372/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5546 - accuracy: 0.8001 - val_loss: 0.3738 - val_accuracy: 0.8961\n",
      "Epoch 373/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5832 - accuracy: 0.7922 - val_loss: 0.3938 - val_accuracy: 0.8831\n",
      "Epoch 374/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5749 - accuracy: 0.8030 - val_loss: 0.3885 - val_accuracy: 0.8896\n",
      "Epoch 375/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5790 - accuracy: 0.8016 - val_loss: 0.3670 - val_accuracy: 0.8961\n",
      "Epoch 376/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5605 - accuracy: 0.8117 - val_loss: 0.3648 - val_accuracy: 0.8961\n",
      "Epoch 377/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5674 - accuracy: 0.7944 - val_loss: 0.3818 - val_accuracy: 0.8896\n",
      "Epoch 378/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5778 - accuracy: 0.8023 - val_loss: 0.3776 - val_accuracy: 0.8896\n",
      "Epoch 379/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5952 - accuracy: 0.7872 - val_loss: 0.3724 - val_accuracy: 0.9026\n",
      "Epoch 380/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5812 - accuracy: 0.7807 - val_loss: 0.3807 - val_accuracy: 0.8896\n",
      "Epoch 381/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5448 - accuracy: 0.8074 - val_loss: 0.3980 - val_accuracy: 0.8506\n",
      "Epoch 382/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5897 - accuracy: 0.7937 - val_loss: 0.3857 - val_accuracy: 0.8831\n",
      "Epoch 383/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5801 - accuracy: 0.7908 - val_loss: 0.3587 - val_accuracy: 0.9091\n",
      "Epoch 384/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5572 - accuracy: 0.7929 - val_loss: 0.3554 - val_accuracy: 0.9026\n",
      "Epoch 385/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5750 - accuracy: 0.7872 - val_loss: 0.3673 - val_accuracy: 0.8961\n",
      "Epoch 386/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5826 - accuracy: 0.7958 - val_loss: 0.3917 - val_accuracy: 0.8766\n",
      "Epoch 387/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5755 - accuracy: 0.7937 - val_loss: 0.3905 - val_accuracy: 0.8766\n",
      "Epoch 388/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5312 - accuracy: 0.8167 - val_loss: 0.3657 - val_accuracy: 0.9026\n",
      "Epoch 389/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5778 - accuracy: 0.8030 - val_loss: 0.3602 - val_accuracy: 0.9026\n",
      "Epoch 390/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5737 - accuracy: 0.8023 - val_loss: 0.3813 - val_accuracy: 0.8766\n",
      "Epoch 391/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5733 - accuracy: 0.8016 - val_loss: 0.3952 - val_accuracy: 0.8766\n",
      "Epoch 392/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5513 - accuracy: 0.8045 - val_loss: 0.3829 - val_accuracy: 0.8896\n",
      "Epoch 393/1000\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5336 - accuracy: 0.8146 - val_loss: 0.3577 - val_accuracy: 0.9026\n",
      "Epoch 394/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5502 - accuracy: 0.8052 - val_loss: 0.3564 - val_accuracy: 0.8961\n",
      "Epoch 395/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5665 - accuracy: 0.7951 - val_loss: 0.3686 - val_accuracy: 0.9026\n",
      "Epoch 396/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5604 - accuracy: 0.7994 - val_loss: 0.3904 - val_accuracy: 0.8831\n",
      "Epoch 397/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5640 - accuracy: 0.8052 - val_loss: 0.3999 - val_accuracy: 0.8701\n",
      "Epoch 398/1000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5546 - accuracy: 0.8146 - val_loss: 0.3774 - val_accuracy: 0.8961\n",
      "Epoch 399/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5517 - accuracy: 0.8009 - val_loss: 0.3612 - val_accuracy: 0.9026\n",
      "Epoch 400/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5409 - accuracy: 0.8066 - val_loss: 0.3682 - val_accuracy: 0.9026\n",
      "Epoch 401/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5866 - accuracy: 0.7835 - val_loss: 0.3796 - val_accuracy: 0.8896\n",
      "Epoch 402/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5688 - accuracy: 0.7886 - val_loss: 0.3831 - val_accuracy: 0.8896\n",
      "Epoch 403/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5802 - accuracy: 0.7929 - val_loss: 0.3809 - val_accuracy: 0.8896\n",
      "Epoch 404/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5494 - accuracy: 0.8160 - val_loss: 0.3712 - val_accuracy: 0.9026\n",
      "Epoch 405/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5635 - accuracy: 0.8102 - val_loss: 0.3694 - val_accuracy: 0.9026\n",
      "Epoch 406/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5602 - accuracy: 0.8030 - val_loss: 0.3759 - val_accuracy: 0.8961\n",
      "Epoch 407/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5468 - accuracy: 0.8052 - val_loss: 0.3775 - val_accuracy: 0.8961\n",
      "Epoch 408/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5542 - accuracy: 0.8052 - val_loss: 0.3781 - val_accuracy: 0.8766\n",
      "Epoch 409/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5466 - accuracy: 0.7965 - val_loss: 0.3778 - val_accuracy: 0.8896\n",
      "Epoch 410/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5464 - accuracy: 0.8001 - val_loss: 0.3837 - val_accuracy: 0.8896\n",
      "Epoch 411/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5540 - accuracy: 0.7987 - val_loss: 0.3854 - val_accuracy: 0.8896\n",
      "Epoch 412/1000\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5633 - accuracy: 0.8038 - val_loss: 0.3749 - val_accuracy: 0.8961\n",
      "Epoch 413/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5526 - accuracy: 0.8124 - val_loss: 0.3724 - val_accuracy: 0.8961\n",
      "Epoch 414/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5610 - accuracy: 0.8045 - val_loss: 0.3737 - val_accuracy: 0.8961\n",
      "Epoch 415/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5384 - accuracy: 0.8059 - val_loss: 0.3738 - val_accuracy: 0.8961\n",
      "Epoch 416/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5601 - accuracy: 0.8016 - val_loss: 0.3749 - val_accuracy: 0.9026\n",
      "Epoch 417/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5485 - accuracy: 0.8038 - val_loss: 0.3715 - val_accuracy: 0.8961\n",
      "Epoch 418/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5489 - accuracy: 0.8160 - val_loss: 0.3712 - val_accuracy: 0.8896\n",
      "Epoch 419/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5554 - accuracy: 0.8030 - val_loss: 0.3802 - val_accuracy: 0.8896\n",
      "Epoch 420/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5504 - accuracy: 0.8102 - val_loss: 0.3787 - val_accuracy: 0.9026\n",
      "Epoch 421/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5369 - accuracy: 0.8153 - val_loss: 0.3703 - val_accuracy: 0.9091\n",
      "Epoch 422/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5363 - accuracy: 0.8167 - val_loss: 0.3698 - val_accuracy: 0.9091\n",
      "Epoch 423/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5589 - accuracy: 0.8059 - val_loss: 0.3818 - val_accuracy: 0.8896\n",
      "Epoch 424/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5364 - accuracy: 0.8139 - val_loss: 0.3928 - val_accuracy: 0.8831\n",
      "Epoch 425/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5805 - accuracy: 0.7872 - val_loss: 0.3860 - val_accuracy: 0.8961\n",
      "Epoch 426/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5613 - accuracy: 0.7965 - val_loss: 0.3756 - val_accuracy: 0.9026\n",
      "Epoch 427/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5474 - accuracy: 0.8117 - val_loss: 0.3822 - val_accuracy: 0.8961\n",
      "Epoch 428/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5349 - accuracy: 0.8038 - val_loss: 0.3900 - val_accuracy: 0.8831\n",
      "Epoch 429/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5340 - accuracy: 0.8059 - val_loss: 0.3764 - val_accuracy: 0.8961\n",
      "Epoch 430/1000\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5070 - accuracy: 0.8268 - val_loss: 0.3656 - val_accuracy: 0.9026\n",
      "Epoch 431/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5605 - accuracy: 0.8023 - val_loss: 0.3803 - val_accuracy: 0.8961\n",
      "Epoch 432/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5512 - accuracy: 0.8232 - val_loss: 0.3883 - val_accuracy: 0.8896\n",
      "Epoch 433/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5409 - accuracy: 0.8110 - val_loss: 0.3812 - val_accuracy: 0.8831\n",
      "Epoch 434/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5511 - accuracy: 0.8030 - val_loss: 0.3639 - val_accuracy: 0.8961\n",
      "Epoch 435/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5682 - accuracy: 0.7980 - val_loss: 0.3585 - val_accuracy: 0.8961\n",
      "Epoch 436/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5420 - accuracy: 0.8110 - val_loss: 0.3773 - val_accuracy: 0.8766\n",
      "Epoch 437/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5176 - accuracy: 0.8196 - val_loss: 0.3851 - val_accuracy: 0.8896\n",
      "Epoch 438/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5398 - accuracy: 0.8160 - val_loss: 0.3752 - val_accuracy: 0.8896\n",
      "Epoch 439/1000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5385 - accuracy: 0.8160 - val_loss: 0.3636 - val_accuracy: 0.9026\n",
      "Epoch 440/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5431 - accuracy: 0.8117 - val_loss: 0.3564 - val_accuracy: 0.9091\n",
      "Epoch 441/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5635 - accuracy: 0.8045 - val_loss: 0.3605 - val_accuracy: 0.9091\n",
      "Epoch 442/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5250 - accuracy: 0.8146 - val_loss: 0.3767 - val_accuracy: 0.8961\n",
      "Epoch 443/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5781 - accuracy: 0.8023 - val_loss: 0.3811 - val_accuracy: 0.8766\n",
      "Epoch 444/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5631 - accuracy: 0.8074 - val_loss: 0.3714 - val_accuracy: 0.8961\n",
      "Epoch 445/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5130 - accuracy: 0.8211 - val_loss: 0.3724 - val_accuracy: 0.8896\n",
      "Epoch 446/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5322 - accuracy: 0.8110 - val_loss: 0.3770 - val_accuracy: 0.8896\n",
      "Epoch 447/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5286 - accuracy: 0.8189 - val_loss: 0.3682 - val_accuracy: 0.8961\n",
      "Epoch 448/1000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5529 - accuracy: 0.8045 - val_loss: 0.3704 - val_accuracy: 0.9026\n",
      "Epoch 449/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5450 - accuracy: 0.8189 - val_loss: 0.3726 - val_accuracy: 0.9091\n",
      "Epoch 450/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5307 - accuracy: 0.8052 - val_loss: 0.3818 - val_accuracy: 0.8896\n",
      "Epoch 451/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5691 - accuracy: 0.7965 - val_loss: 0.3768 - val_accuracy: 0.8896\n",
      "Epoch 452/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5401 - accuracy: 0.8074 - val_loss: 0.3554 - val_accuracy: 0.9091\n",
      "Epoch 453/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5367 - accuracy: 0.8066 - val_loss: 0.3497 - val_accuracy: 0.9156\n",
      "Epoch 454/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5589 - accuracy: 0.8059 - val_loss: 0.3573 - val_accuracy: 0.9091\n",
      "Epoch 455/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5349 - accuracy: 0.8117 - val_loss: 0.3685 - val_accuracy: 0.8961\n",
      "Epoch 456/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5254 - accuracy: 0.8074 - val_loss: 0.3762 - val_accuracy: 0.9091\n",
      "Epoch 457/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5644 - accuracy: 0.7900 - val_loss: 0.3797 - val_accuracy: 0.8961\n",
      "Epoch 458/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5387 - accuracy: 0.8117 - val_loss: 0.3722 - val_accuracy: 0.8961\n",
      "Epoch 459/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5262 - accuracy: 0.8203 - val_loss: 0.3626 - val_accuracy: 0.8961\n",
      "Epoch 460/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5492 - accuracy: 0.8045 - val_loss: 0.3648 - val_accuracy: 0.9091\n",
      "Epoch 461/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5489 - accuracy: 0.8175 - val_loss: 0.3664 - val_accuracy: 0.9091\n",
      "Epoch 462/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5577 - accuracy: 0.7987 - val_loss: 0.3652 - val_accuracy: 0.9156\n",
      "Epoch 463/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5097 - accuracy: 0.8218 - val_loss: 0.3665 - val_accuracy: 0.9091\n",
      "Epoch 464/1000\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5430 - accuracy: 0.8081 - val_loss: 0.3649 - val_accuracy: 0.9221\n",
      "Epoch 465/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5312 - accuracy: 0.8038 - val_loss: 0.3660 - val_accuracy: 0.9026\n",
      "Epoch 466/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5496 - accuracy: 0.8088 - val_loss: 0.3627 - val_accuracy: 0.9026\n",
      "Epoch 467/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5104 - accuracy: 0.8081 - val_loss: 0.3648 - val_accuracy: 0.9091\n",
      "Epoch 468/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5334 - accuracy: 0.8052 - val_loss: 0.3655 - val_accuracy: 0.9026\n",
      "Epoch 469/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5411 - accuracy: 0.8066 - val_loss: 0.3624 - val_accuracy: 0.9026\n",
      "Epoch 470/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5656 - accuracy: 0.7900 - val_loss: 0.3605 - val_accuracy: 0.9026\n",
      "Epoch 471/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5224 - accuracy: 0.8124 - val_loss: 0.3535 - val_accuracy: 0.9156\n",
      "Epoch 472/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5419 - accuracy: 0.8066 - val_loss: 0.3509 - val_accuracy: 0.9156\n",
      "Epoch 473/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5281 - accuracy: 0.8196 - val_loss: 0.3596 - val_accuracy: 0.9091\n",
      "Epoch 474/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5771 - accuracy: 0.8009 - val_loss: 0.3659 - val_accuracy: 0.9091\n",
      "Epoch 475/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5545 - accuracy: 0.8023 - val_loss: 0.3604 - val_accuracy: 0.9091\n",
      "Epoch 476/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5298 - accuracy: 0.8254 - val_loss: 0.3628 - val_accuracy: 0.9091\n",
      "Epoch 477/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5544 - accuracy: 0.8066 - val_loss: 0.3698 - val_accuracy: 0.9026\n",
      "Epoch 478/1000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5489 - accuracy: 0.8045 - val_loss: 0.3720 - val_accuracy: 0.9091\n",
      "Epoch 479/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5126 - accuracy: 0.8189 - val_loss: 0.3616 - val_accuracy: 0.9091\n",
      "Epoch 480/1000\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5407 - accuracy: 0.8095 - val_loss: 0.3554 - val_accuracy: 0.9091\n",
      "Epoch 481/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5398 - accuracy: 0.8066 - val_loss: 0.3568 - val_accuracy: 0.9091\n",
      "Epoch 482/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5147 - accuracy: 0.8160 - val_loss: 0.3558 - val_accuracy: 0.9091\n",
      "Epoch 483/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5244 - accuracy: 0.8117 - val_loss: 0.3494 - val_accuracy: 0.9091\n",
      "Epoch 484/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5188 - accuracy: 0.8124 - val_loss: 0.3459 - val_accuracy: 0.9156\n",
      "Epoch 485/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5290 - accuracy: 0.8110 - val_loss: 0.3501 - val_accuracy: 0.9026\n",
      "Epoch 486/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5362 - accuracy: 0.8009 - val_loss: 0.3557 - val_accuracy: 0.9026\n",
      "Epoch 487/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5123 - accuracy: 0.8182 - val_loss: 0.3653 - val_accuracy: 0.9091\n",
      "Epoch 488/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5155 - accuracy: 0.8203 - val_loss: 0.3630 - val_accuracy: 0.8961\n",
      "Epoch 489/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5131 - accuracy: 0.8254 - val_loss: 0.3491 - val_accuracy: 0.9026\n",
      "Epoch 490/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5321 - accuracy: 0.8139 - val_loss: 0.3416 - val_accuracy: 0.9156\n",
      "Epoch 491/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5602 - accuracy: 0.8023 - val_loss: 0.3455 - val_accuracy: 0.9156\n",
      "Epoch 492/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5279 - accuracy: 0.8081 - val_loss: 0.3574 - val_accuracy: 0.9091\n",
      "Epoch 493/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5232 - accuracy: 0.8167 - val_loss: 0.3553 - val_accuracy: 0.8961\n",
      "Epoch 494/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5100 - accuracy: 0.8268 - val_loss: 0.3522 - val_accuracy: 0.8961\n",
      "Epoch 495/1000\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5199 - accuracy: 0.8146 - val_loss: 0.3616 - val_accuracy: 0.8896\n",
      "Epoch 496/1000\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5299 - accuracy: 0.8167 - val_loss: 0.3677 - val_accuracy: 0.8896\n",
      "Epoch 497/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5574 - accuracy: 0.8081 - val_loss: 0.3570 - val_accuracy: 0.9026\n",
      "Epoch 498/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5241 - accuracy: 0.8225 - val_loss: 0.3501 - val_accuracy: 0.9156\n",
      "Epoch 499/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5471 - accuracy: 0.8052 - val_loss: 0.3456 - val_accuracy: 0.9026\n",
      "Epoch 500/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5326 - accuracy: 0.8124 - val_loss: 0.3531 - val_accuracy: 0.9026\n",
      "Epoch 501/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5562 - accuracy: 0.8023 - val_loss: 0.3651 - val_accuracy: 0.9091\n",
      "Epoch 502/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5107 - accuracy: 0.8175 - val_loss: 0.3705 - val_accuracy: 0.8961\n",
      "Epoch 503/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5356 - accuracy: 0.8167 - val_loss: 0.3620 - val_accuracy: 0.8896\n",
      "Epoch 504/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5314 - accuracy: 0.8110 - val_loss: 0.3572 - val_accuracy: 0.9091\n",
      "Epoch 505/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5357 - accuracy: 0.7980 - val_loss: 0.3455 - val_accuracy: 0.9091\n",
      "Epoch 506/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5159 - accuracy: 0.8131 - val_loss: 0.3534 - val_accuracy: 0.9091\n",
      "Epoch 507/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5275 - accuracy: 0.8146 - val_loss: 0.3662 - val_accuracy: 0.9026\n",
      "Epoch 508/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5527 - accuracy: 0.8139 - val_loss: 0.3776 - val_accuracy: 0.8961\n",
      "Epoch 509/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5161 - accuracy: 0.8139 - val_loss: 0.3648 - val_accuracy: 0.8961\n",
      "Epoch 510/1000\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5277 - accuracy: 0.8160 - val_loss: 0.3484 - val_accuracy: 0.9091\n",
      "Epoch 511/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5027 - accuracy: 0.8203 - val_loss: 0.3539 - val_accuracy: 0.9091\n",
      "Epoch 512/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5204 - accuracy: 0.8167 - val_loss: 0.3609 - val_accuracy: 0.9026\n",
      "Epoch 513/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5218 - accuracy: 0.8182 - val_loss: 0.3658 - val_accuracy: 0.9026\n",
      "Epoch 514/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5244 - accuracy: 0.8160 - val_loss: 0.3697 - val_accuracy: 0.8961\n",
      "Epoch 515/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5205 - accuracy: 0.8146 - val_loss: 0.3536 - val_accuracy: 0.9026\n",
      "Epoch 516/1000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5374 - accuracy: 0.8139 - val_loss: 0.3432 - val_accuracy: 0.9026\n",
      "Epoch 517/1000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5333 - accuracy: 0.8110 - val_loss: 0.3576 - val_accuracy: 0.9026\n",
      "Epoch 518/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5105 - accuracy: 0.8268 - val_loss: 0.3678 - val_accuracy: 0.9026\n",
      "Epoch 519/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5341 - accuracy: 0.8110 - val_loss: 0.3506 - val_accuracy: 0.9156\n",
      "Epoch 520/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5260 - accuracy: 0.8146 - val_loss: 0.3457 - val_accuracy: 0.9156\n",
      "Epoch 521/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5027 - accuracy: 0.8110 - val_loss: 0.3572 - val_accuracy: 0.9026\n",
      "Epoch 522/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5171 - accuracy: 0.8117 - val_loss: 0.3618 - val_accuracy: 0.9091\n",
      "Epoch 523/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4931 - accuracy: 0.8203 - val_loss: 0.3584 - val_accuracy: 0.9091\n",
      "Epoch 524/1000\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5303 - accuracy: 0.8139 - val_loss: 0.3471 - val_accuracy: 0.9156\n",
      "Epoch 525/1000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5374 - accuracy: 0.8139 - val_loss: 0.3480 - val_accuracy: 0.9091\n",
      "Epoch 526/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5292 - accuracy: 0.8117 - val_loss: 0.3624 - val_accuracy: 0.9091\n",
      "Epoch 527/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5221 - accuracy: 0.8247 - val_loss: 0.3692 - val_accuracy: 0.9091\n",
      "Epoch 528/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5119 - accuracy: 0.8160 - val_loss: 0.3657 - val_accuracy: 0.9091\n",
      "Epoch 529/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5202 - accuracy: 0.8102 - val_loss: 0.3454 - val_accuracy: 0.9026\n",
      "Epoch 530/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5467 - accuracy: 0.7937 - val_loss: 0.3466 - val_accuracy: 0.9026\n",
      "Epoch 531/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5334 - accuracy: 0.8102 - val_loss: 0.3678 - val_accuracy: 0.9026\n",
      "Epoch 532/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5352 - accuracy: 0.8203 - val_loss: 0.3689 - val_accuracy: 0.8961\n",
      "Epoch 533/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5431 - accuracy: 0.8009 - val_loss: 0.3518 - val_accuracy: 0.9026\n",
      "Epoch 534/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5237 - accuracy: 0.8110 - val_loss: 0.3514 - val_accuracy: 0.9026\n",
      "Epoch 535/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5158 - accuracy: 0.8095 - val_loss: 0.3616 - val_accuracy: 0.8896\n",
      "Epoch 536/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5145 - accuracy: 0.8131 - val_loss: 0.3720 - val_accuracy: 0.8961\n",
      "Epoch 537/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5101 - accuracy: 0.8160 - val_loss: 0.3761 - val_accuracy: 0.8961\n",
      "Epoch 538/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5399 - accuracy: 0.8081 - val_loss: 0.3608 - val_accuracy: 0.9091\n",
      "Epoch 539/1000\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5097 - accuracy: 0.8203 - val_loss: 0.3575 - val_accuracy: 0.9091\n",
      "Epoch 540/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5322 - accuracy: 0.8117 - val_loss: 0.3467 - val_accuracy: 0.9026\n",
      "Epoch 541/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5481 - accuracy: 0.8059 - val_loss: 0.3469 - val_accuracy: 0.9091\n",
      "Epoch 542/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5529 - accuracy: 0.8038 - val_loss: 0.3606 - val_accuracy: 0.9026\n",
      "Epoch 543/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5188 - accuracy: 0.8095 - val_loss: 0.3839 - val_accuracy: 0.8896\n",
      "Epoch 544/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5225 - accuracy: 0.8052 - val_loss: 0.3662 - val_accuracy: 0.9026\n",
      "Epoch 545/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5217 - accuracy: 0.8153 - val_loss: 0.3389 - val_accuracy: 0.9026\n",
      "Epoch 546/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5292 - accuracy: 0.8139 - val_loss: 0.3401 - val_accuracy: 0.9156\n",
      "Epoch 547/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5302 - accuracy: 0.8066 - val_loss: 0.3490 - val_accuracy: 0.9156\n",
      "Epoch 548/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5261 - accuracy: 0.8095 - val_loss: 0.3580 - val_accuracy: 0.9156\n",
      "Epoch 549/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4839 - accuracy: 0.8240 - val_loss: 0.3657 - val_accuracy: 0.9091\n",
      "Epoch 550/1000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5102 - accuracy: 0.8319 - val_loss: 0.3571 - val_accuracy: 0.9156\n",
      "Epoch 551/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5387 - accuracy: 0.8052 - val_loss: 0.3362 - val_accuracy: 0.9091\n",
      "Epoch 552/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5112 - accuracy: 0.8218 - val_loss: 0.3413 - val_accuracy: 0.9026\n",
      "Epoch 553/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5427 - accuracy: 0.8023 - val_loss: 0.3606 - val_accuracy: 0.9026\n",
      "Epoch 554/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5464 - accuracy: 0.8110 - val_loss: 0.3734 - val_accuracy: 0.9026\n",
      "Epoch 555/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5080 - accuracy: 0.8276 - val_loss: 0.3649 - val_accuracy: 0.9156\n",
      "Epoch 556/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5088 - accuracy: 0.8232 - val_loss: 0.3494 - val_accuracy: 0.9156\n",
      "Epoch 557/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5308 - accuracy: 0.8088 - val_loss: 0.3350 - val_accuracy: 0.9221\n",
      "Epoch 558/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5105 - accuracy: 0.8175 - val_loss: 0.3447 - val_accuracy: 0.9156\n",
      "Epoch 559/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5070 - accuracy: 0.8167 - val_loss: 0.3579 - val_accuracy: 0.8896\n",
      "Epoch 560/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5425 - accuracy: 0.8066 - val_loss: 0.3709 - val_accuracy: 0.8896\n",
      "Epoch 561/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5317 - accuracy: 0.8066 - val_loss: 0.3708 - val_accuracy: 0.8961\n",
      "Epoch 562/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4922 - accuracy: 0.8247 - val_loss: 0.3556 - val_accuracy: 0.9026\n",
      "Epoch 563/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5243 - accuracy: 0.8240 - val_loss: 0.3426 - val_accuracy: 0.9026\n",
      "Epoch 564/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4915 - accuracy: 0.8254 - val_loss: 0.3454 - val_accuracy: 0.9156\n",
      "Epoch 565/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5414 - accuracy: 0.8074 - val_loss: 0.3403 - val_accuracy: 0.9091\n",
      "Epoch 566/1000\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5024 - accuracy: 0.8131 - val_loss: 0.3368 - val_accuracy: 0.9091\n",
      "Epoch 567/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5040 - accuracy: 0.8196 - val_loss: 0.3361 - val_accuracy: 0.9026\n",
      "Epoch 568/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4881 - accuracy: 0.8254 - val_loss: 0.3452 - val_accuracy: 0.8961\n",
      "Epoch 569/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5087 - accuracy: 0.8175 - val_loss: 0.3520 - val_accuracy: 0.9026\n",
      "Epoch 570/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5259 - accuracy: 0.8102 - val_loss: 0.3386 - val_accuracy: 0.9091\n",
      "Epoch 571/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5203 - accuracy: 0.8218 - val_loss: 0.3400 - val_accuracy: 0.9091\n",
      "Epoch 572/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5396 - accuracy: 0.8045 - val_loss: 0.3610 - val_accuracy: 0.8961\n",
      "Epoch 573/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5358 - accuracy: 0.8030 - val_loss: 0.3638 - val_accuracy: 0.8961\n",
      "Epoch 574/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5211 - accuracy: 0.8102 - val_loss: 0.3499 - val_accuracy: 0.9026\n",
      "Epoch 575/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5052 - accuracy: 0.8139 - val_loss: 0.3421 - val_accuracy: 0.9156\n",
      "Epoch 576/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5260 - accuracy: 0.8074 - val_loss: 0.3452 - val_accuracy: 0.9091\n",
      "Epoch 577/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5135 - accuracy: 0.8211 - val_loss: 0.3556 - val_accuracy: 0.8961\n",
      "Epoch 578/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4885 - accuracy: 0.8232 - val_loss: 0.3602 - val_accuracy: 0.9026\n",
      "Epoch 579/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4961 - accuracy: 0.8304 - val_loss: 0.3472 - val_accuracy: 0.9026\n",
      "Epoch 580/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5169 - accuracy: 0.8139 - val_loss: 0.3380 - val_accuracy: 0.9156\n",
      "Epoch 581/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4838 - accuracy: 0.8254 - val_loss: 0.3438 - val_accuracy: 0.9091\n",
      "Epoch 582/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5496 - accuracy: 0.8016 - val_loss: 0.3476 - val_accuracy: 0.9091\n",
      "Epoch 583/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5327 - accuracy: 0.8117 - val_loss: 0.3570 - val_accuracy: 0.8896\n",
      "Epoch 584/1000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5051 - accuracy: 0.8232 - val_loss: 0.3529 - val_accuracy: 0.8961\n",
      "Epoch 585/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5266 - accuracy: 0.8117 - val_loss: 0.3453 - val_accuracy: 0.9091\n",
      "Epoch 586/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5335 - accuracy: 0.8066 - val_loss: 0.3387 - val_accuracy: 0.8961\n",
      "Epoch 587/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5144 - accuracy: 0.8052 - val_loss: 0.3414 - val_accuracy: 0.8961\n",
      "Epoch 588/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4935 - accuracy: 0.8254 - val_loss: 0.3533 - val_accuracy: 0.8961\n",
      "Epoch 589/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5275 - accuracy: 0.8139 - val_loss: 0.3570 - val_accuracy: 0.9091\n",
      "Epoch 590/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5006 - accuracy: 0.8189 - val_loss: 0.3469 - val_accuracy: 0.9026\n",
      "Epoch 591/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5079 - accuracy: 0.8276 - val_loss: 0.3432 - val_accuracy: 0.9026\n",
      "Epoch 592/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4930 - accuracy: 0.8175 - val_loss: 0.3415 - val_accuracy: 0.9091\n",
      "Epoch 593/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4765 - accuracy: 0.8369 - val_loss: 0.3357 - val_accuracy: 0.9026\n",
      "Epoch 594/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5190 - accuracy: 0.8059 - val_loss: 0.3363 - val_accuracy: 0.9026\n",
      "Epoch 595/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5137 - accuracy: 0.8189 - val_loss: 0.3511 - val_accuracy: 0.9026\n",
      "Epoch 596/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4967 - accuracy: 0.8254 - val_loss: 0.3749 - val_accuracy: 0.8961\n",
      "Epoch 597/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5155 - accuracy: 0.8182 - val_loss: 0.3687 - val_accuracy: 0.8896\n",
      "Epoch 598/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5232 - accuracy: 0.8146 - val_loss: 0.3460 - val_accuracy: 0.9026\n",
      "Epoch 599/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4670 - accuracy: 0.8427 - val_loss: 0.3355 - val_accuracy: 0.9091\n",
      "Epoch 600/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5175 - accuracy: 0.8081 - val_loss: 0.3548 - val_accuracy: 0.9091\n",
      "Epoch 601/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5023 - accuracy: 0.8225 - val_loss: 0.3795 - val_accuracy: 0.8831\n",
      "Epoch 602/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5336 - accuracy: 0.8038 - val_loss: 0.3780 - val_accuracy: 0.8831\n",
      "Epoch 603/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5216 - accuracy: 0.8124 - val_loss: 0.3540 - val_accuracy: 0.8961\n",
      "Epoch 604/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5284 - accuracy: 0.8268 - val_loss: 0.3391 - val_accuracy: 0.9091\n",
      "Epoch 605/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5412 - accuracy: 0.8146 - val_loss: 0.3493 - val_accuracy: 0.9156\n",
      "Epoch 606/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5065 - accuracy: 0.8189 - val_loss: 0.3580 - val_accuracy: 0.9026\n",
      "Epoch 607/1000\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5119 - accuracy: 0.8175 - val_loss: 0.3712 - val_accuracy: 0.8961\n",
      "Epoch 608/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5205 - accuracy: 0.8102 - val_loss: 0.3687 - val_accuracy: 0.8896\n",
      "Epoch 609/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5309 - accuracy: 0.8052 - val_loss: 0.3546 - val_accuracy: 0.8961\n",
      "Epoch 610/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5269 - accuracy: 0.8124 - val_loss: 0.3372 - val_accuracy: 0.9026\n",
      "Epoch 611/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5369 - accuracy: 0.8081 - val_loss: 0.3471 - val_accuracy: 0.8961\n",
      "Epoch 612/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5138 - accuracy: 0.8240 - val_loss: 0.3546 - val_accuracy: 0.8961\n",
      "Epoch 613/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4938 - accuracy: 0.8189 - val_loss: 0.3559 - val_accuracy: 0.9026\n",
      "Epoch 614/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5199 - accuracy: 0.8110 - val_loss: 0.3498 - val_accuracy: 0.9091\n",
      "Epoch 615/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4821 - accuracy: 0.8240 - val_loss: 0.3576 - val_accuracy: 0.8961\n",
      "Epoch 616/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5051 - accuracy: 0.8189 - val_loss: 0.3666 - val_accuracy: 0.8896\n",
      "Epoch 617/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4834 - accuracy: 0.8110 - val_loss: 0.3723 - val_accuracy: 0.8961\n",
      "Epoch 618/1000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5161 - accuracy: 0.8088 - val_loss: 0.3567 - val_accuracy: 0.8896\n",
      "Epoch 619/1000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4979 - accuracy: 0.8095 - val_loss: 0.3411 - val_accuracy: 0.9026\n",
      "Epoch 620/1000\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4679 - accuracy: 0.8247 - val_loss: 0.3409 - val_accuracy: 0.9091\n",
      "Epoch 621/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5068 - accuracy: 0.8218 - val_loss: 0.3514 - val_accuracy: 0.9091\n",
      "Epoch 622/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5007 - accuracy: 0.8297 - val_loss: 0.3666 - val_accuracy: 0.9091\n",
      "Epoch 623/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5018 - accuracy: 0.8167 - val_loss: 0.3713 - val_accuracy: 0.8961\n",
      "Epoch 624/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4728 - accuracy: 0.8240 - val_loss: 0.3550 - val_accuracy: 0.8961\n",
      "Epoch 625/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5147 - accuracy: 0.8189 - val_loss: 0.3526 - val_accuracy: 0.9026\n",
      "Epoch 626/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5014 - accuracy: 0.8218 - val_loss: 0.3624 - val_accuracy: 0.8961\n",
      "Epoch 627/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5179 - accuracy: 0.8102 - val_loss: 0.3648 - val_accuracy: 0.9091\n",
      "Epoch 628/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4876 - accuracy: 0.8283 - val_loss: 0.3456 - val_accuracy: 0.9156\n",
      "Epoch 629/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5133 - accuracy: 0.8146 - val_loss: 0.3450 - val_accuracy: 0.9156\n",
      "Epoch 630/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5195 - accuracy: 0.8016 - val_loss: 0.3495 - val_accuracy: 0.9091\n",
      "Epoch 631/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5077 - accuracy: 0.8203 - val_loss: 0.3647 - val_accuracy: 0.9026\n",
      "Epoch 632/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5118 - accuracy: 0.8139 - val_loss: 0.3720 - val_accuracy: 0.8896\n",
      "Epoch 633/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4776 - accuracy: 0.8319 - val_loss: 0.3611 - val_accuracy: 0.8961\n",
      "Epoch 634/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5333 - accuracy: 0.8110 - val_loss: 0.3528 - val_accuracy: 0.8961\n",
      "Epoch 635/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5078 - accuracy: 0.8124 - val_loss: 0.3592 - val_accuracy: 0.9026\n",
      "Epoch 636/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5130 - accuracy: 0.8146 - val_loss: 0.3597 - val_accuracy: 0.9091\n",
      "Epoch 637/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5026 - accuracy: 0.8117 - val_loss: 0.3625 - val_accuracy: 0.8961\n",
      "Epoch 638/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4776 - accuracy: 0.8225 - val_loss: 0.3527 - val_accuracy: 0.9091\n",
      "Epoch 639/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5195 - accuracy: 0.8131 - val_loss: 0.3458 - val_accuracy: 0.9026\n",
      "Epoch 640/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5132 - accuracy: 0.8124 - val_loss: 0.3467 - val_accuracy: 0.9026\n",
      "Epoch 641/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4804 - accuracy: 0.8196 - val_loss: 0.3556 - val_accuracy: 0.8961\n",
      "Epoch 642/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5003 - accuracy: 0.8225 - val_loss: 0.3650 - val_accuracy: 0.9026\n",
      "Epoch 643/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5035 - accuracy: 0.8074 - val_loss: 0.3626 - val_accuracy: 0.8961\n",
      "Epoch 644/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4745 - accuracy: 0.8225 - val_loss: 0.3498 - val_accuracy: 0.9026\n",
      "Epoch 645/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5067 - accuracy: 0.8247 - val_loss: 0.3352 - val_accuracy: 0.9091\n",
      "Epoch 646/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5218 - accuracy: 0.8146 - val_loss: 0.3481 - val_accuracy: 0.8896\n",
      "Epoch 647/1000\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5179 - accuracy: 0.8175 - val_loss: 0.3633 - val_accuracy: 0.8961\n",
      "Epoch 648/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5024 - accuracy: 0.8153 - val_loss: 0.3615 - val_accuracy: 0.8961\n",
      "Epoch 649/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5113 - accuracy: 0.8146 - val_loss: 0.3467 - val_accuracy: 0.9026\n",
      "Epoch 650/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5016 - accuracy: 0.8218 - val_loss: 0.3442 - val_accuracy: 0.8961\n",
      "Epoch 651/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5051 - accuracy: 0.8261 - val_loss: 0.3491 - val_accuracy: 0.8961\n",
      "Epoch 652/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5340 - accuracy: 0.7980 - val_loss: 0.3499 - val_accuracy: 0.8896\n",
      "Epoch 653/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4976 - accuracy: 0.8189 - val_loss: 0.3424 - val_accuracy: 0.9026\n",
      "Epoch 654/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4924 - accuracy: 0.8167 - val_loss: 0.3318 - val_accuracy: 0.9026\n",
      "Epoch 655/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4953 - accuracy: 0.8160 - val_loss: 0.3394 - val_accuracy: 0.9091\n",
      "Epoch 656/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5348 - accuracy: 0.8146 - val_loss: 0.3580 - val_accuracy: 0.9091\n",
      "Epoch 657/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5364 - accuracy: 0.7994 - val_loss: 0.3491 - val_accuracy: 0.8961\n",
      "Epoch 658/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5058 - accuracy: 0.8203 - val_loss: 0.3380 - val_accuracy: 0.9026\n",
      "Epoch 659/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4813 - accuracy: 0.8319 - val_loss: 0.3507 - val_accuracy: 0.8961\n",
      "Epoch 660/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5002 - accuracy: 0.8247 - val_loss: 0.3696 - val_accuracy: 0.8896\n",
      "Epoch 661/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4965 - accuracy: 0.8167 - val_loss: 0.3652 - val_accuracy: 0.9026\n",
      "Epoch 662/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5048 - accuracy: 0.8247 - val_loss: 0.3555 - val_accuracy: 0.9091\n",
      "Epoch 663/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4929 - accuracy: 0.8290 - val_loss: 0.3388 - val_accuracy: 0.9026\n",
      "Epoch 664/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4931 - accuracy: 0.8146 - val_loss: 0.3366 - val_accuracy: 0.9026\n",
      "Epoch 665/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5014 - accuracy: 0.8124 - val_loss: 0.3360 - val_accuracy: 0.9091\n",
      "Epoch 666/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5135 - accuracy: 0.8066 - val_loss: 0.3529 - val_accuracy: 0.9026\n",
      "Epoch 667/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5010 - accuracy: 0.8167 - val_loss: 0.3699 - val_accuracy: 0.8896\n",
      "Epoch 668/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4950 - accuracy: 0.8117 - val_loss: 0.3607 - val_accuracy: 0.8961\n",
      "Epoch 669/1000\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5376 - accuracy: 0.8059 - val_loss: 0.3478 - val_accuracy: 0.9026\n",
      "Epoch 670/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4865 - accuracy: 0.8312 - val_loss: 0.3541 - val_accuracy: 0.8961\n",
      "Epoch 671/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5054 - accuracy: 0.8139 - val_loss: 0.3637 - val_accuracy: 0.8961\n",
      "Epoch 672/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5093 - accuracy: 0.8131 - val_loss: 0.3555 - val_accuracy: 0.9091\n",
      "Epoch 673/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5003 - accuracy: 0.8182 - val_loss: 0.3372 - val_accuracy: 0.9026\n",
      "Epoch 674/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5145 - accuracy: 0.8124 - val_loss: 0.3326 - val_accuracy: 0.9156\n",
      "Epoch 675/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5281 - accuracy: 0.8102 - val_loss: 0.3540 - val_accuracy: 0.8961\n",
      "Epoch 676/1000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5364 - accuracy: 0.8001 - val_loss: 0.3644 - val_accuracy: 0.8896\n",
      "Epoch 677/1000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5312 - accuracy: 0.8102 - val_loss: 0.3505 - val_accuracy: 0.8896\n",
      "Epoch 678/1000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5038 - accuracy: 0.8153 - val_loss: 0.3385 - val_accuracy: 0.8961\n",
      "Epoch 679/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5186 - accuracy: 0.8095 - val_loss: 0.3472 - val_accuracy: 0.8896\n",
      "Epoch 680/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4997 - accuracy: 0.8304 - val_loss: 0.3522 - val_accuracy: 0.8961\n",
      "Epoch 681/1000\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5024 - accuracy: 0.8254 - val_loss: 0.3692 - val_accuracy: 0.9026\n",
      "Epoch 682/1000\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5552 - accuracy: 0.7893 - val_loss: 0.3493 - val_accuracy: 0.9026\n",
      "Epoch 683/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5363 - accuracy: 0.8045 - val_loss: 0.3283 - val_accuracy: 0.9026\n",
      "Epoch 684/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5097 - accuracy: 0.8196 - val_loss: 0.3314 - val_accuracy: 0.9026\n",
      "Epoch 685/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5107 - accuracy: 0.8232 - val_loss: 0.3531 - val_accuracy: 0.8961\n",
      "Epoch 686/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5205 - accuracy: 0.8153 - val_loss: 0.3542 - val_accuracy: 0.9026\n",
      "Epoch 687/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5226 - accuracy: 0.8059 - val_loss: 0.3396 - val_accuracy: 0.9026\n",
      "Epoch 688/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5014 - accuracy: 0.8240 - val_loss: 0.3344 - val_accuracy: 0.8961\n",
      "Epoch 689/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5523 - accuracy: 0.7980 - val_loss: 0.3518 - val_accuracy: 0.8896\n",
      "Epoch 690/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4919 - accuracy: 0.8254 - val_loss: 0.3621 - val_accuracy: 0.8831\n",
      "Epoch 691/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5149 - accuracy: 0.8167 - val_loss: 0.3529 - val_accuracy: 0.8896\n",
      "Epoch 692/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5325 - accuracy: 0.8016 - val_loss: 0.3418 - val_accuracy: 0.9026\n",
      "Epoch 693/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4775 - accuracy: 0.8261 - val_loss: 0.3478 - val_accuracy: 0.9026\n",
      "Epoch 694/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5064 - accuracy: 0.8074 - val_loss: 0.3476 - val_accuracy: 0.8896\n",
      "Epoch 695/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5140 - accuracy: 0.8182 - val_loss: 0.3419 - val_accuracy: 0.9091\n",
      "Epoch 696/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5277 - accuracy: 0.8102 - val_loss: 0.3472 - val_accuracy: 0.9091\n",
      "Epoch 697/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4849 - accuracy: 0.8218 - val_loss: 0.3427 - val_accuracy: 0.8961\n",
      "Epoch 698/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5340 - accuracy: 0.8081 - val_loss: 0.3362 - val_accuracy: 0.8961\n",
      "Epoch 699/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4727 - accuracy: 0.8355 - val_loss: 0.3294 - val_accuracy: 0.9091\n",
      "Epoch 700/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4930 - accuracy: 0.8175 - val_loss: 0.3316 - val_accuracy: 0.9156\n",
      "Epoch 701/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5049 - accuracy: 0.8189 - val_loss: 0.3481 - val_accuracy: 0.9026\n",
      "Epoch 702/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4833 - accuracy: 0.8153 - val_loss: 0.3480 - val_accuracy: 0.8896\n",
      "Epoch 703/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5086 - accuracy: 0.8196 - val_loss: 0.3438 - val_accuracy: 0.8896\n",
      "Epoch 704/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4989 - accuracy: 0.8124 - val_loss: 0.3434 - val_accuracy: 0.8896\n",
      "Epoch 705/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5046 - accuracy: 0.8196 - val_loss: 0.3355 - val_accuracy: 0.9026\n",
      "Epoch 706/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5047 - accuracy: 0.8153 - val_loss: 0.3325 - val_accuracy: 0.9026\n",
      "Epoch 707/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4955 - accuracy: 0.8182 - val_loss: 0.3328 - val_accuracy: 0.9091\n",
      "Epoch 708/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4570 - accuracy: 0.8319 - val_loss: 0.3385 - val_accuracy: 0.9091\n",
      "Epoch 709/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5238 - accuracy: 0.8038 - val_loss: 0.3387 - val_accuracy: 0.8896\n",
      "Epoch 710/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5125 - accuracy: 0.8052 - val_loss: 0.3408 - val_accuracy: 0.8896\n",
      "Epoch 711/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5080 - accuracy: 0.8023 - val_loss: 0.3401 - val_accuracy: 0.8831\n",
      "Epoch 712/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4773 - accuracy: 0.8160 - val_loss: 0.3339 - val_accuracy: 0.8961\n",
      "Epoch 713/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5080 - accuracy: 0.8211 - val_loss: 0.3377 - val_accuracy: 0.8961\n",
      "Epoch 714/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5082 - accuracy: 0.8240 - val_loss: 0.3497 - val_accuracy: 0.9091\n",
      "Epoch 715/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5159 - accuracy: 0.8167 - val_loss: 0.3499 - val_accuracy: 0.8961\n",
      "Epoch 716/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4980 - accuracy: 0.8203 - val_loss: 0.3432 - val_accuracy: 0.9091\n",
      "Epoch 717/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4724 - accuracy: 0.8240 - val_loss: 0.3314 - val_accuracy: 0.9091\n",
      "Epoch 718/1000\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4782 - accuracy: 0.8413 - val_loss: 0.3267 - val_accuracy: 0.9026\n",
      "Epoch 719/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4805 - accuracy: 0.8276 - val_loss: 0.3363 - val_accuracy: 0.8831\n",
      "Epoch 720/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4803 - accuracy: 0.8247 - val_loss: 0.3495 - val_accuracy: 0.8831\n",
      "Epoch 721/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4909 - accuracy: 0.8146 - val_loss: 0.3584 - val_accuracy: 0.8961\n",
      "Epoch 722/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4707 - accuracy: 0.8326 - val_loss: 0.3513 - val_accuracy: 0.8831\n",
      "Epoch 723/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4884 - accuracy: 0.8254 - val_loss: 0.3393 - val_accuracy: 0.8896\n",
      "Epoch 724/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4825 - accuracy: 0.8218 - val_loss: 0.3455 - val_accuracy: 0.8896\n",
      "Epoch 725/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4967 - accuracy: 0.8074 - val_loss: 0.3523 - val_accuracy: 0.8961\n",
      "Epoch 726/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4674 - accuracy: 0.8369 - val_loss: 0.3481 - val_accuracy: 0.8896\n",
      "Epoch 727/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4876 - accuracy: 0.8225 - val_loss: 0.3381 - val_accuracy: 0.8896\n",
      "Epoch 728/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5030 - accuracy: 0.8153 - val_loss: 0.3305 - val_accuracy: 0.9026\n",
      "Epoch 729/1000\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5148 - accuracy: 0.8175 - val_loss: 0.3296 - val_accuracy: 0.9221\n",
      "Epoch 730/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5268 - accuracy: 0.8095 - val_loss: 0.3444 - val_accuracy: 0.9091\n",
      "Epoch 731/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4997 - accuracy: 0.8124 - val_loss: 0.3587 - val_accuracy: 0.8896\n",
      "Epoch 732/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4875 - accuracy: 0.8254 - val_loss: 0.3432 - val_accuracy: 0.8896\n",
      "Epoch 733/1000\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4955 - accuracy: 0.8167 - val_loss: 0.3191 - val_accuracy: 0.9156\n",
      "Epoch 734/1000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5140 - accuracy: 0.8139 - val_loss: 0.3281 - val_accuracy: 0.9091\n",
      "Epoch 735/1000\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4886 - accuracy: 0.8218 - val_loss: 0.3528 - val_accuracy: 0.8961\n",
      "Epoch 736/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4867 - accuracy: 0.8182 - val_loss: 0.3661 - val_accuracy: 0.9026\n",
      "Epoch 737/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4958 - accuracy: 0.8153 - val_loss: 0.3495 - val_accuracy: 0.9026\n",
      "Epoch 738/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5090 - accuracy: 0.8088 - val_loss: 0.3351 - val_accuracy: 0.9156\n",
      "Epoch 739/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4944 - accuracy: 0.8218 - val_loss: 0.3285 - val_accuracy: 0.9026\n",
      "Epoch 740/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5116 - accuracy: 0.8175 - val_loss: 0.3408 - val_accuracy: 0.8961\n",
      "Epoch 741/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4939 - accuracy: 0.8139 - val_loss: 0.3395 - val_accuracy: 0.8961\n",
      "Epoch 742/1000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4930 - accuracy: 0.8297 - val_loss: 0.3250 - val_accuracy: 0.8961\n",
      "Epoch 743/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4856 - accuracy: 0.8189 - val_loss: 0.3278 - val_accuracy: 0.9091\n",
      "Epoch 744/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4781 - accuracy: 0.8189 - val_loss: 0.3375 - val_accuracy: 0.9026\n",
      "Epoch 745/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5123 - accuracy: 0.8095 - val_loss: 0.3444 - val_accuracy: 0.8961\n",
      "Epoch 746/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4718 - accuracy: 0.8218 - val_loss: 0.3443 - val_accuracy: 0.8961\n",
      "Epoch 747/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5122 - accuracy: 0.8066 - val_loss: 0.3333 - val_accuracy: 0.9026\n",
      "Epoch 748/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4958 - accuracy: 0.8189 - val_loss: 0.3312 - val_accuracy: 0.9026\n",
      "Epoch 749/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4864 - accuracy: 0.8240 - val_loss: 0.3333 - val_accuracy: 0.9026\n",
      "Epoch 750/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4897 - accuracy: 0.8203 - val_loss: 0.3390 - val_accuracy: 0.9091\n",
      "Epoch 751/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5162 - accuracy: 0.8117 - val_loss: 0.3400 - val_accuracy: 0.9026\n",
      "Epoch 752/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5013 - accuracy: 0.8225 - val_loss: 0.3375 - val_accuracy: 0.9026\n",
      "Epoch 753/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4788 - accuracy: 0.8268 - val_loss: 0.3289 - val_accuracy: 0.9091\n",
      "Epoch 754/1000\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4937 - accuracy: 0.8160 - val_loss: 0.3398 - val_accuracy: 0.9026\n",
      "Epoch 755/1000\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4909 - accuracy: 0.8182 - val_loss: 0.3688 - val_accuracy: 0.8961\n",
      "Epoch 756/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5052 - accuracy: 0.8110 - val_loss: 0.3569 - val_accuracy: 0.8961\n",
      "Epoch 757/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5349 - accuracy: 0.7973 - val_loss: 0.3331 - val_accuracy: 0.9026\n",
      "Epoch 758/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4915 - accuracy: 0.8225 - val_loss: 0.3168 - val_accuracy: 0.9026\n",
      "Epoch 759/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5039 - accuracy: 0.8117 - val_loss: 0.3273 - val_accuracy: 0.8896\n",
      "Epoch 760/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4774 - accuracy: 0.8268 - val_loss: 0.3477 - val_accuracy: 0.8831\n",
      "Epoch 761/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4688 - accuracy: 0.8189 - val_loss: 0.3587 - val_accuracy: 0.8831\n",
      "Epoch 762/1000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5021 - accuracy: 0.8146 - val_loss: 0.3624 - val_accuracy: 0.9026\n",
      "Epoch 763/1000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5163 - accuracy: 0.8052 - val_loss: 0.3402 - val_accuracy: 0.9091\n",
      "Epoch 764/1000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5026 - accuracy: 0.8261 - val_loss: 0.3374 - val_accuracy: 0.8961\n",
      "Epoch 765/1000\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4983 - accuracy: 0.8333 - val_loss: 0.3406 - val_accuracy: 0.8961\n",
      "Epoch 766/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5100 - accuracy: 0.8095 - val_loss: 0.3414 - val_accuracy: 0.8896\n",
      "Epoch 767/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4680 - accuracy: 0.8312 - val_loss: 0.3404 - val_accuracy: 0.8831\n",
      "Epoch 768/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5296 - accuracy: 0.8074 - val_loss: 0.3489 - val_accuracy: 0.8961\n",
      "Epoch 769/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4825 - accuracy: 0.8167 - val_loss: 0.3432 - val_accuracy: 0.9026\n",
      "Epoch 770/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4927 - accuracy: 0.8247 - val_loss: 0.3351 - val_accuracy: 0.9026\n",
      "Epoch 771/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5065 - accuracy: 0.8182 - val_loss: 0.3324 - val_accuracy: 0.9091\n",
      "Epoch 772/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4908 - accuracy: 0.8254 - val_loss: 0.3300 - val_accuracy: 0.9091\n",
      "Epoch 773/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4750 - accuracy: 0.8232 - val_loss: 0.3297 - val_accuracy: 0.9026\n",
      "Epoch 774/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5091 - accuracy: 0.8088 - val_loss: 0.3455 - val_accuracy: 0.8896\n",
      "Epoch 775/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4784 - accuracy: 0.8276 - val_loss: 0.3489 - val_accuracy: 0.8831\n",
      "Epoch 776/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4841 - accuracy: 0.8276 - val_loss: 0.3467 - val_accuracy: 0.8961\n",
      "Epoch 777/1000\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4784 - accuracy: 0.8189 - val_loss: 0.3463 - val_accuracy: 0.8896\n",
      "Epoch 778/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5224 - accuracy: 0.8102 - val_loss: 0.3434 - val_accuracy: 0.8831\n",
      "Epoch 779/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4727 - accuracy: 0.8211 - val_loss: 0.3407 - val_accuracy: 0.8896\n",
      "Epoch 780/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4887 - accuracy: 0.8240 - val_loss: 0.3334 - val_accuracy: 0.8961\n",
      "Epoch 781/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4718 - accuracy: 0.8290 - val_loss: 0.3375 - val_accuracy: 0.9026\n",
      "Epoch 782/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4953 - accuracy: 0.8312 - val_loss: 0.3518 - val_accuracy: 0.8896\n",
      "Epoch 783/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4650 - accuracy: 0.8276 - val_loss: 0.3560 - val_accuracy: 0.9091\n",
      "Epoch 784/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5307 - accuracy: 0.8139 - val_loss: 0.3481 - val_accuracy: 0.9156\n",
      "Epoch 785/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4788 - accuracy: 0.8139 - val_loss: 0.3329 - val_accuracy: 0.8896\n",
      "Epoch 786/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4851 - accuracy: 0.8225 - val_loss: 0.3309 - val_accuracy: 0.8896\n",
      "Epoch 787/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4878 - accuracy: 0.8247 - val_loss: 0.3429 - val_accuracy: 0.8896\n",
      "Epoch 788/1000\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4682 - accuracy: 0.8196 - val_loss: 0.3633 - val_accuracy: 0.8896\n",
      "Epoch 789/1000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5078 - accuracy: 0.8218 - val_loss: 0.3672 - val_accuracy: 0.8961\n",
      "Epoch 790/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5034 - accuracy: 0.8196 - val_loss: 0.3544 - val_accuracy: 0.9026\n",
      "Epoch 791/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5171 - accuracy: 0.8139 - val_loss: 0.3472 - val_accuracy: 0.8896\n",
      "Epoch 792/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4641 - accuracy: 0.8326 - val_loss: 0.3413 - val_accuracy: 0.8961\n",
      "Epoch 793/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4913 - accuracy: 0.8218 - val_loss: 0.3334 - val_accuracy: 0.8896\n",
      "Epoch 794/1000\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4794 - accuracy: 0.8333 - val_loss: 0.3414 - val_accuracy: 0.8961\n",
      "Epoch 795/1000\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4907 - accuracy: 0.8182 - val_loss: 0.3477 - val_accuracy: 0.8961\n",
      "Epoch 796/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4939 - accuracy: 0.8283 - val_loss: 0.3398 - val_accuracy: 0.9026\n",
      "Epoch 797/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4711 - accuracy: 0.8290 - val_loss: 0.3301 - val_accuracy: 0.9026\n",
      "Epoch 798/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4924 - accuracy: 0.8283 - val_loss: 0.3276 - val_accuracy: 0.8961\n",
      "Epoch 799/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4892 - accuracy: 0.8232 - val_loss: 0.3453 - val_accuracy: 0.8831\n",
      "Epoch 800/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4546 - accuracy: 0.8391 - val_loss: 0.3653 - val_accuracy: 0.8831\n",
      "Epoch 801/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5247 - accuracy: 0.8095 - val_loss: 0.3654 - val_accuracy: 0.8896\n",
      "Epoch 802/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4639 - accuracy: 0.8326 - val_loss: 0.3367 - val_accuracy: 0.8961\n",
      "Epoch 803/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4673 - accuracy: 0.8420 - val_loss: 0.3226 - val_accuracy: 0.9156\n",
      "Epoch 804/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4998 - accuracy: 0.8196 - val_loss: 0.3324 - val_accuracy: 0.8896\n",
      "Epoch 805/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4696 - accuracy: 0.8384 - val_loss: 0.3583 - val_accuracy: 0.8831\n",
      "Epoch 806/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4854 - accuracy: 0.8167 - val_loss: 0.3626 - val_accuracy: 0.8831\n",
      "Epoch 807/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4851 - accuracy: 0.8232 - val_loss: 0.3449 - val_accuracy: 0.8831\n",
      "Epoch 808/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4667 - accuracy: 0.8276 - val_loss: 0.3325 - val_accuracy: 0.9156\n",
      "Epoch 809/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4865 - accuracy: 0.8203 - val_loss: 0.3334 - val_accuracy: 0.9156\n",
      "Epoch 810/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4951 - accuracy: 0.8232 - val_loss: 0.3361 - val_accuracy: 0.9091\n",
      "Epoch 811/1000\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4760 - accuracy: 0.8268 - val_loss: 0.3453 - val_accuracy: 0.9026\n",
      "Epoch 812/1000\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4826 - accuracy: 0.8290 - val_loss: 0.3462 - val_accuracy: 0.8896\n",
      "Epoch 813/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4898 - accuracy: 0.8196 - val_loss: 0.3369 - val_accuracy: 0.8961\n",
      "Epoch 814/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5123 - accuracy: 0.8102 - val_loss: 0.3211 - val_accuracy: 0.9091\n",
      "Epoch 815/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4713 - accuracy: 0.8312 - val_loss: 0.3278 - val_accuracy: 0.9091\n",
      "Epoch 816/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4580 - accuracy: 0.8232 - val_loss: 0.3537 - val_accuracy: 0.9026\n",
      "Epoch 817/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4981 - accuracy: 0.8131 - val_loss: 0.3744 - val_accuracy: 0.9091\n",
      "Epoch 818/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5260 - accuracy: 0.8045 - val_loss: 0.3745 - val_accuracy: 0.8896\n",
      "Epoch 819/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5033 - accuracy: 0.8225 - val_loss: 0.3488 - val_accuracy: 0.8831\n",
      "Epoch 820/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4875 - accuracy: 0.8254 - val_loss: 0.3432 - val_accuracy: 0.9026\n",
      "Epoch 821/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4967 - accuracy: 0.8139 - val_loss: 0.3552 - val_accuracy: 0.8896\n",
      "Epoch 822/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5133 - accuracy: 0.8247 - val_loss: 0.3612 - val_accuracy: 0.8896\n",
      "Epoch 823/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4974 - accuracy: 0.8240 - val_loss: 0.3514 - val_accuracy: 0.8896\n",
      "Epoch 824/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5068 - accuracy: 0.8088 - val_loss: 0.3410 - val_accuracy: 0.8961\n",
      "Epoch 825/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5077 - accuracy: 0.8182 - val_loss: 0.3378 - val_accuracy: 0.8896\n",
      "Epoch 826/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5156 - accuracy: 0.8153 - val_loss: 0.3548 - val_accuracy: 0.8831\n",
      "Epoch 827/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4850 - accuracy: 0.8167 - val_loss: 0.3629 - val_accuracy: 0.8831\n",
      "Epoch 828/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5324 - accuracy: 0.8124 - val_loss: 0.3527 - val_accuracy: 0.8896\n",
      "Epoch 829/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5055 - accuracy: 0.8182 - val_loss: 0.3492 - val_accuracy: 0.8831\n",
      "Epoch 830/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5007 - accuracy: 0.8189 - val_loss: 0.3528 - val_accuracy: 0.8896\n",
      "Epoch 831/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4798 - accuracy: 0.8211 - val_loss: 0.3551 - val_accuracy: 0.8831\n",
      "Epoch 832/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4659 - accuracy: 0.8218 - val_loss: 0.3552 - val_accuracy: 0.8766\n",
      "Epoch 833/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5085 - accuracy: 0.8196 - val_loss: 0.3481 - val_accuracy: 0.8896\n",
      "Epoch 834/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4989 - accuracy: 0.8182 - val_loss: 0.3415 - val_accuracy: 0.8831\n",
      "Epoch 835/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4999 - accuracy: 0.8261 - val_loss: 0.3447 - val_accuracy: 0.8896\n",
      "Epoch 836/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4839 - accuracy: 0.8254 - val_loss: 0.3310 - val_accuracy: 0.8896\n",
      "Epoch 837/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5044 - accuracy: 0.8225 - val_loss: 0.3371 - val_accuracy: 0.9026\n",
      "Epoch 838/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4932 - accuracy: 0.8268 - val_loss: 0.3531 - val_accuracy: 0.8896\n",
      "Epoch 839/1000\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4743 - accuracy: 0.8355 - val_loss: 0.3529 - val_accuracy: 0.8831\n",
      "Epoch 840/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5031 - accuracy: 0.8218 - val_loss: 0.3498 - val_accuracy: 0.8896\n",
      "Epoch 841/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4994 - accuracy: 0.8110 - val_loss: 0.3434 - val_accuracy: 0.8896\n",
      "Epoch 842/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4718 - accuracy: 0.8326 - val_loss: 0.3396 - val_accuracy: 0.8831\n",
      "Epoch 843/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4917 - accuracy: 0.8218 - val_loss: 0.3469 - val_accuracy: 0.9026\n",
      "Epoch 844/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5029 - accuracy: 0.8240 - val_loss: 0.3571 - val_accuracy: 0.8961\n",
      "Epoch 845/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5030 - accuracy: 0.8225 - val_loss: 0.3616 - val_accuracy: 0.8961\n",
      "Epoch 846/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4862 - accuracy: 0.8182 - val_loss: 0.3551 - val_accuracy: 0.8961\n",
      "Epoch 847/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4958 - accuracy: 0.8160 - val_loss: 0.3521 - val_accuracy: 0.8961\n",
      "Epoch 848/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4883 - accuracy: 0.8254 - val_loss: 0.3382 - val_accuracy: 0.8961\n",
      "Epoch 849/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4982 - accuracy: 0.8139 - val_loss: 0.3386 - val_accuracy: 0.8961\n",
      "Epoch 850/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4840 - accuracy: 0.8240 - val_loss: 0.3502 - val_accuracy: 0.8896\n",
      "Epoch 851/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4799 - accuracy: 0.8297 - val_loss: 0.3581 - val_accuracy: 0.8896\n",
      "Epoch 852/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4907 - accuracy: 0.8182 - val_loss: 0.3542 - val_accuracy: 0.8961\n",
      "Epoch 853/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4997 - accuracy: 0.8167 - val_loss: 0.3417 - val_accuracy: 0.9026\n",
      "Epoch 854/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4687 - accuracy: 0.8326 - val_loss: 0.3375 - val_accuracy: 0.8961\n",
      "Epoch 855/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4902 - accuracy: 0.8160 - val_loss: 0.3447 - val_accuracy: 0.9091\n",
      "Epoch 856/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4849 - accuracy: 0.8261 - val_loss: 0.3654 - val_accuracy: 0.9026\n",
      "Epoch 857/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4933 - accuracy: 0.8146 - val_loss: 0.3568 - val_accuracy: 0.8896\n",
      "Epoch 858/1000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4883 - accuracy: 0.8153 - val_loss: 0.3219 - val_accuracy: 0.9091\n",
      "Epoch 859/1000\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5000 - accuracy: 0.8117 - val_loss: 0.3164 - val_accuracy: 0.8896\n",
      "Epoch 860/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5127 - accuracy: 0.8153 - val_loss: 0.3311 - val_accuracy: 0.8896\n",
      "Epoch 861/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5011 - accuracy: 0.8167 - val_loss: 0.3565 - val_accuracy: 0.8896\n",
      "Epoch 862/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4667 - accuracy: 0.8319 - val_loss: 0.3752 - val_accuracy: 0.8766\n",
      "Epoch 863/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5150 - accuracy: 0.8175 - val_loss: 0.3668 - val_accuracy: 0.8766\n",
      "Epoch 864/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4891 - accuracy: 0.8247 - val_loss: 0.3320 - val_accuracy: 0.8831\n",
      "Epoch 865/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5128 - accuracy: 0.8211 - val_loss: 0.3151 - val_accuracy: 0.8961\n",
      "Epoch 866/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4679 - accuracy: 0.8254 - val_loss: 0.3206 - val_accuracy: 0.8896\n",
      "Epoch 867/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5039 - accuracy: 0.8131 - val_loss: 0.3260 - val_accuracy: 0.9091\n",
      "Epoch 868/1000\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4682 - accuracy: 0.8319 - val_loss: 0.3420 - val_accuracy: 0.9026\n",
      "Epoch 869/1000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4713 - accuracy: 0.8355 - val_loss: 0.3514 - val_accuracy: 0.8896\n",
      "Epoch 870/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4786 - accuracy: 0.8189 - val_loss: 0.3418 - val_accuracy: 0.8896\n",
      "Epoch 871/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4991 - accuracy: 0.8124 - val_loss: 0.3318 - val_accuracy: 0.8896\n",
      "Epoch 872/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4625 - accuracy: 0.8268 - val_loss: 0.3338 - val_accuracy: 0.8896\n",
      "Epoch 873/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4780 - accuracy: 0.8225 - val_loss: 0.3446 - val_accuracy: 0.8961\n",
      "Epoch 874/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4767 - accuracy: 0.8254 - val_loss: 0.3572 - val_accuracy: 0.8896\n",
      "Epoch 875/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4921 - accuracy: 0.8153 - val_loss: 0.3484 - val_accuracy: 0.8766\n",
      "Epoch 876/1000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4832 - accuracy: 0.8225 - val_loss: 0.3319 - val_accuracy: 0.8896\n",
      "Epoch 877/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4918 - accuracy: 0.8240 - val_loss: 0.3363 - val_accuracy: 0.8896\n",
      "Epoch 878/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4876 - accuracy: 0.8261 - val_loss: 0.3526 - val_accuracy: 0.8831\n",
      "Epoch 879/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5029 - accuracy: 0.8153 - val_loss: 0.3761 - val_accuracy: 0.8831\n",
      "Epoch 880/1000\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5033 - accuracy: 0.8167 - val_loss: 0.3803 - val_accuracy: 0.8701\n",
      "Epoch 881/1000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4555 - accuracy: 0.8341 - val_loss: 0.3417 - val_accuracy: 0.8896\n",
      "Epoch 882/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4920 - accuracy: 0.8167 - val_loss: 0.3338 - val_accuracy: 0.8896\n",
      "Epoch 883/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4877 - accuracy: 0.8167 - val_loss: 0.3372 - val_accuracy: 0.9026\n",
      "Epoch 884/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5094 - accuracy: 0.8081 - val_loss: 0.3390 - val_accuracy: 0.9026\n",
      "Epoch 885/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4774 - accuracy: 0.8283 - val_loss: 0.3432 - val_accuracy: 0.8896\n",
      "Epoch 886/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4669 - accuracy: 0.8290 - val_loss: 0.3498 - val_accuracy: 0.8831\n",
      "Epoch 887/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4409 - accuracy: 0.8369 - val_loss: 0.3500 - val_accuracy: 0.8896\n",
      "Epoch 888/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4909 - accuracy: 0.8261 - val_loss: 0.3461 - val_accuracy: 0.8961\n",
      "Epoch 889/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4937 - accuracy: 0.8189 - val_loss: 0.3315 - val_accuracy: 0.8896\n",
      "Epoch 890/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5130 - accuracy: 0.8110 - val_loss: 0.3240 - val_accuracy: 0.9026\n",
      "Epoch 891/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4745 - accuracy: 0.8384 - val_loss: 0.3328 - val_accuracy: 0.8961\n",
      "Epoch 892/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4717 - accuracy: 0.8326 - val_loss: 0.3539 - val_accuracy: 0.8896\n",
      "Epoch 893/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4743 - accuracy: 0.8211 - val_loss: 0.3593 - val_accuracy: 0.8961\n",
      "Epoch 894/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5059 - accuracy: 0.8160 - val_loss: 0.3409 - val_accuracy: 0.8961\n",
      "Epoch 895/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4876 - accuracy: 0.8189 - val_loss: 0.3222 - val_accuracy: 0.9026\n",
      "Epoch 896/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5039 - accuracy: 0.8139 - val_loss: 0.3139 - val_accuracy: 0.9026\n",
      "Epoch 897/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4803 - accuracy: 0.8124 - val_loss: 0.3249 - val_accuracy: 0.9091\n",
      "Epoch 898/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4684 - accuracy: 0.8247 - val_loss: 0.3305 - val_accuracy: 0.9091\n",
      "Epoch 899/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4675 - accuracy: 0.8276 - val_loss: 0.3365 - val_accuracy: 0.9091\n",
      "Epoch 900/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4901 - accuracy: 0.8218 - val_loss: 0.3419 - val_accuracy: 0.8961\n",
      "Epoch 901/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5011 - accuracy: 0.8160 - val_loss: 0.3473 - val_accuracy: 0.8896\n",
      "Epoch 902/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4862 - accuracy: 0.8203 - val_loss: 0.3564 - val_accuracy: 0.8831\n",
      "Epoch 903/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4901 - accuracy: 0.8160 - val_loss: 0.3567 - val_accuracy: 0.8896\n",
      "Epoch 904/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5432 - accuracy: 0.8052 - val_loss: 0.3508 - val_accuracy: 0.9026\n",
      "Epoch 905/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4364 - accuracy: 0.8427 - val_loss: 0.3510 - val_accuracy: 0.9026\n",
      "Epoch 906/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4723 - accuracy: 0.8247 - val_loss: 0.3582 - val_accuracy: 0.8831\n",
      "Epoch 907/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4957 - accuracy: 0.8247 - val_loss: 0.3657 - val_accuracy: 0.8831\n",
      "Epoch 908/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4727 - accuracy: 0.8225 - val_loss: 0.3538 - val_accuracy: 0.9026\n",
      "Epoch 909/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4643 - accuracy: 0.8362 - val_loss: 0.3385 - val_accuracy: 0.9026\n",
      "Epoch 910/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4907 - accuracy: 0.8117 - val_loss: 0.3340 - val_accuracy: 0.8961\n",
      "Epoch 911/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4583 - accuracy: 0.8304 - val_loss: 0.3401 - val_accuracy: 0.8896\n",
      "Epoch 912/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5004 - accuracy: 0.8146 - val_loss: 0.3480 - val_accuracy: 0.8831\n",
      "Epoch 913/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4602 - accuracy: 0.8304 - val_loss: 0.3495 - val_accuracy: 0.8896\n",
      "Epoch 914/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4854 - accuracy: 0.8225 - val_loss: 0.3402 - val_accuracy: 0.8896\n",
      "Epoch 915/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5080 - accuracy: 0.8175 - val_loss: 0.3476 - val_accuracy: 0.8896\n",
      "Epoch 916/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4544 - accuracy: 0.8369 - val_loss: 0.3640 - val_accuracy: 0.8961\n",
      "Epoch 917/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4699 - accuracy: 0.8319 - val_loss: 0.3684 - val_accuracy: 0.8961\n",
      "Epoch 918/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4673 - accuracy: 0.8333 - val_loss: 0.3468 - val_accuracy: 0.8961\n",
      "Epoch 919/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4841 - accuracy: 0.8254 - val_loss: 0.3246 - val_accuracy: 0.8961\n",
      "Epoch 920/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5060 - accuracy: 0.8153 - val_loss: 0.3266 - val_accuracy: 0.8961\n",
      "Epoch 921/1000\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4729 - accuracy: 0.8290 - val_loss: 0.3432 - val_accuracy: 0.8961\n",
      "Epoch 922/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4832 - accuracy: 0.8203 - val_loss: 0.3593 - val_accuracy: 0.8896\n",
      "Epoch 923/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4685 - accuracy: 0.8312 - val_loss: 0.3578 - val_accuracy: 0.8896\n",
      "Epoch 924/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4530 - accuracy: 0.8391 - val_loss: 0.3421 - val_accuracy: 0.8896\n",
      "Epoch 925/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5016 - accuracy: 0.8211 - val_loss: 0.3305 - val_accuracy: 0.9026\n",
      "Epoch 926/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5054 - accuracy: 0.8211 - val_loss: 0.3315 - val_accuracy: 0.9026\n",
      "Epoch 927/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4627 - accuracy: 0.8355 - val_loss: 0.3390 - val_accuracy: 0.8961\n",
      "Epoch 928/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4800 - accuracy: 0.8312 - val_loss: 0.3400 - val_accuracy: 0.9091\n",
      "Epoch 929/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4865 - accuracy: 0.8261 - val_loss: 0.3444 - val_accuracy: 0.8961\n",
      "Epoch 930/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5150 - accuracy: 0.8182 - val_loss: 0.3437 - val_accuracy: 0.9026\n",
      "Epoch 931/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4540 - accuracy: 0.8377 - val_loss: 0.3478 - val_accuracy: 0.8961\n",
      "Epoch 932/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5006 - accuracy: 0.8203 - val_loss: 0.3570 - val_accuracy: 0.8961\n",
      "Epoch 933/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4921 - accuracy: 0.8189 - val_loss: 0.3600 - val_accuracy: 0.9091\n",
      "Epoch 934/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4649 - accuracy: 0.8196 - val_loss: 0.3549 - val_accuracy: 0.9026\n",
      "Epoch 935/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4877 - accuracy: 0.8218 - val_loss: 0.3478 - val_accuracy: 0.9091\n",
      "Epoch 936/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4776 - accuracy: 0.8211 - val_loss: 0.3460 - val_accuracy: 0.9026\n",
      "Epoch 937/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5033 - accuracy: 0.8102 - val_loss: 0.3538 - val_accuracy: 0.8961\n",
      "Epoch 938/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4788 - accuracy: 0.8254 - val_loss: 0.3554 - val_accuracy: 0.8896\n",
      "Epoch 939/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4915 - accuracy: 0.8211 - val_loss: 0.3474 - val_accuracy: 0.8896\n",
      "Epoch 940/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4792 - accuracy: 0.8276 - val_loss: 0.3387 - val_accuracy: 0.8961\n",
      "Epoch 941/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5150 - accuracy: 0.8081 - val_loss: 0.3498 - val_accuracy: 0.8961\n",
      "Epoch 942/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5020 - accuracy: 0.8102 - val_loss: 0.3582 - val_accuracy: 0.8896\n",
      "Epoch 943/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4856 - accuracy: 0.8247 - val_loss: 0.3547 - val_accuracy: 0.8961\n",
      "Epoch 944/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4953 - accuracy: 0.8160 - val_loss: 0.3491 - val_accuracy: 0.8961\n",
      "Epoch 945/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4904 - accuracy: 0.8232 - val_loss: 0.3428 - val_accuracy: 0.9026\n",
      "Epoch 946/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4864 - accuracy: 0.8319 - val_loss: 0.3430 - val_accuracy: 0.8961\n",
      "Epoch 947/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4544 - accuracy: 0.8341 - val_loss: 0.3538 - val_accuracy: 0.8896\n",
      "Epoch 948/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5237 - accuracy: 0.8052 - val_loss: 0.3567 - val_accuracy: 0.8896\n",
      "Epoch 949/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4899 - accuracy: 0.8182 - val_loss: 0.3604 - val_accuracy: 0.8831\n",
      "Epoch 950/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4691 - accuracy: 0.8297 - val_loss: 0.3406 - val_accuracy: 0.9026\n",
      "Epoch 951/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4949 - accuracy: 0.8189 - val_loss: 0.3289 - val_accuracy: 0.8961\n",
      "Epoch 952/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4817 - accuracy: 0.8211 - val_loss: 0.3345 - val_accuracy: 0.8896\n",
      "Epoch 953/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5055 - accuracy: 0.8175 - val_loss: 0.3437 - val_accuracy: 0.9026\n",
      "Epoch 954/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5089 - accuracy: 0.8088 - val_loss: 0.3598 - val_accuracy: 0.8896\n",
      "Epoch 955/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4901 - accuracy: 0.8261 - val_loss: 0.3608 - val_accuracy: 0.8896\n",
      "Epoch 956/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4699 - accuracy: 0.8254 - val_loss: 0.3504 - val_accuracy: 0.8896\n",
      "Epoch 957/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4784 - accuracy: 0.8268 - val_loss: 0.3419 - val_accuracy: 0.8831\n",
      "Epoch 958/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4613 - accuracy: 0.8355 - val_loss: 0.3392 - val_accuracy: 0.8896\n",
      "Epoch 959/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4931 - accuracy: 0.8268 - val_loss: 0.3460 - val_accuracy: 0.8896\n",
      "Epoch 960/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4840 - accuracy: 0.8146 - val_loss: 0.3593 - val_accuracy: 0.8896\n",
      "Epoch 961/1000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.4936 - accuracy: 0.8110 - val_loss: 0.3585 - val_accuracy: 0.8896\n",
      "Epoch 962/1000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4944 - accuracy: 0.8240 - val_loss: 0.3345 - val_accuracy: 0.8896\n",
      "Epoch 963/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4596 - accuracy: 0.8312 - val_loss: 0.3311 - val_accuracy: 0.8896\n",
      "Epoch 964/1000\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4805 - accuracy: 0.8268 - val_loss: 0.3329 - val_accuracy: 0.8961\n",
      "Epoch 965/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4970 - accuracy: 0.8124 - val_loss: 0.3516 - val_accuracy: 0.8831\n",
      "Epoch 966/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4855 - accuracy: 0.8304 - val_loss: 0.3772 - val_accuracy: 0.8831\n",
      "Epoch 967/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4702 - accuracy: 0.8304 - val_loss: 0.3662 - val_accuracy: 0.8896\n",
      "Epoch 968/1000\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4684 - accuracy: 0.8232 - val_loss: 0.3608 - val_accuracy: 0.8896\n",
      "Epoch 969/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4741 - accuracy: 0.8312 - val_loss: 0.3536 - val_accuracy: 0.8961\n",
      "Epoch 970/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4529 - accuracy: 0.8218 - val_loss: 0.3463 - val_accuracy: 0.8831\n",
      "Epoch 971/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5188 - accuracy: 0.8124 - val_loss: 0.3320 - val_accuracy: 0.8961\n",
      "Epoch 972/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4913 - accuracy: 0.8247 - val_loss: 0.3247 - val_accuracy: 0.9026\n",
      "Epoch 973/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4822 - accuracy: 0.8254 - val_loss: 0.3338 - val_accuracy: 0.9026\n",
      "Epoch 974/1000\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4817 - accuracy: 0.8189 - val_loss: 0.3489 - val_accuracy: 0.8896\n",
      "Epoch 975/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4853 - accuracy: 0.8153 - val_loss: 0.3376 - val_accuracy: 0.8896\n",
      "Epoch 976/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4567 - accuracy: 0.8254 - val_loss: 0.3238 - val_accuracy: 0.8961\n",
      "Epoch 977/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4824 - accuracy: 0.8283 - val_loss: 0.3246 - val_accuracy: 0.8896\n",
      "Epoch 978/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4800 - accuracy: 0.8326 - val_loss: 0.3431 - val_accuracy: 0.8896\n",
      "Epoch 979/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5147 - accuracy: 0.8175 - val_loss: 0.3315 - val_accuracy: 0.9091\n",
      "Epoch 980/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4807 - accuracy: 0.8276 - val_loss: 0.3384 - val_accuracy: 0.8961\n",
      "Epoch 981/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4933 - accuracy: 0.8290 - val_loss: 0.3549 - val_accuracy: 0.8831\n",
      "Epoch 982/1000\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5296 - accuracy: 0.8175 - val_loss: 0.3421 - val_accuracy: 0.8961\n",
      "Epoch 983/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4873 - accuracy: 0.8167 - val_loss: 0.3294 - val_accuracy: 0.8896\n",
      "Epoch 984/1000\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4748 - accuracy: 0.8420 - val_loss: 0.3467 - val_accuracy: 0.8896\n",
      "Epoch 985/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4909 - accuracy: 0.8218 - val_loss: 0.3476 - val_accuracy: 0.9026\n",
      "Epoch 986/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4809 - accuracy: 0.8240 - val_loss: 0.3496 - val_accuracy: 0.8961\n",
      "Epoch 987/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4720 - accuracy: 0.8319 - val_loss: 0.3695 - val_accuracy: 0.8896\n",
      "Epoch 988/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4958 - accuracy: 0.8196 - val_loss: 0.3794 - val_accuracy: 0.8831\n",
      "Epoch 989/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4946 - accuracy: 0.8225 - val_loss: 0.3731 - val_accuracy: 0.8766\n",
      "Epoch 990/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5016 - accuracy: 0.7973 - val_loss: 0.3610 - val_accuracy: 0.8831\n",
      "Epoch 991/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4964 - accuracy: 0.8160 - val_loss: 0.3397 - val_accuracy: 0.8766\n",
      "Epoch 992/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4883 - accuracy: 0.8211 - val_loss: 0.3479 - val_accuracy: 0.8896\n",
      "Epoch 993/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5103 - accuracy: 0.8240 - val_loss: 0.3575 - val_accuracy: 0.8896\n",
      "Epoch 994/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5069 - accuracy: 0.8146 - val_loss: 0.3613 - val_accuracy: 0.8961\n",
      "Epoch 995/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4974 - accuracy: 0.8146 - val_loss: 0.3664 - val_accuracy: 0.8896\n",
      "Epoch 996/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5042 - accuracy: 0.8153 - val_loss: 0.3648 - val_accuracy: 0.8831\n",
      "Epoch 997/1000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4625 - accuracy: 0.8348 - val_loss: 0.3629 - val_accuracy: 0.8831\n",
      "Epoch 998/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4939 - accuracy: 0.8182 - val_loss: 0.3549 - val_accuracy: 0.8831\n",
      "Epoch 999/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4738 - accuracy: 0.8348 - val_loss: 0.3409 - val_accuracy: 0.8896\n",
      "Epoch 1000/1000\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4577 - accuracy: 0.8290 - val_loss: 0.3278 - val_accuracy: 0.8961\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Epoch is 0 and 0.04587512486614287 seconds passed\n",
      "Epoch is 10 and 0.1805247499141842 seconds passed\n",
      "Epoch is 20 and 0.322488916805014 seconds passed\n",
      "Epoch is 30 and 0.4890545830130577 seconds passed\n",
      "Epoch is 40 and 0.6232649169396609 seconds passed\n",
      "Epoch is 50 and 0.7563566248863935 seconds passed\n",
      "Epoch is 60 and 0.8847564999014139 seconds passed\n",
      "Epoch is 70 and 1.0119193329010159 seconds passed\n",
      "Epoch is 80 and 1.1381398749072105 seconds passed\n",
      "Epoch is 90 and 1.269283541943878 seconds passed\n",
      "Epoch is 100 and 1.3925144579261541 seconds passed\n",
      "End of training, took 1.4302087079267949 seconds\n",
      "16/16 [==============================] - 0s 347us/step\n",
      "   Bumps  Dirtiness  K_Scatch  Pastry  Stains  Z_Scratch\n",
      "0     48          7         1       8       4         13\n",
      "1      0         82         0       0       0          1\n",
      "2      9          0        64       4       0          3\n",
      "3      7          3         0      58       0          5\n",
      "4      0          0         0       0      80          0\n",
      "5      9          1         2       1       1         71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.59      0.62        81\n",
      "           1       0.88      0.99      0.93        83\n",
      "           2       0.96      0.80      0.87        80\n",
      "           3       0.82      0.79      0.81        73\n",
      "           4       0.94      1.00      0.97        80\n",
      "           5       0.76      0.84      0.80        85\n",
      "\n",
      "    accuracy                           0.84       482\n",
      "   macro avg       0.84      0.84      0.83       482\n",
      "weighted avg       0.84      0.84      0.83       482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history0 = model.fit(X_train0, y_train0, batch_size= 1024, epochs= 1000,  validation_data=(X_val0, y_val0), callbacks=callback,verbose = 0)\n",
    "y_test_pred = model.predict(X_test0)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=-1)\n",
    "\n",
    "cm = confusion_matrix(y_test0, y_test_pred)\n",
    "cm = pd.DataFrame(cm)\n",
    "cm.columns = ['Bumps', 'Dirtiness', 'K_Scatch', 'Pastry', 'Stains', 'Z_Scratch']\n",
    "print(cm)\n",
    "print(classification_report(y_test0, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Epoch is 0 and 0.025278375018388033 seconds passed\n",
      "Epoch is 10 and 0.152612250065431 seconds passed\n",
      "Epoch is 20 and 0.28506504208780825 seconds passed\n",
      "Epoch is 30 and 0.4191584591753781 seconds passed\n",
      "Epoch is 40 and 0.5571309591177851 seconds passed\n",
      "Epoch is 50 and 0.6816005001310259 seconds passed\n",
      "Epoch is 60 and 0.8085417090915143 seconds passed\n",
      "Epoch is 70 and 0.9371430419851094 seconds passed\n",
      "Epoch is 80 and 1.0774915420915931 seconds passed\n",
      "Epoch is 90 and 1.206271959003061 seconds passed\n",
      "Epoch is 100 and 1.3405832091812044 seconds passed\n",
      "Epoch is 110 and 1.4669387501198798 seconds passed\n",
      "Epoch is 120 and 1.5996215420309454 seconds passed\n",
      "Epoch is 130 and 1.7282301250379533 seconds passed\n",
      "Epoch is 140 and 1.855938667198643 seconds passed\n",
      "Epoch is 150 and 1.9801049591042101 seconds passed\n",
      "Epoch is 160 and 2.1085365421604365 seconds passed\n",
      "Epoch is 170 and 2.2349797091446817 seconds passed\n",
      "Epoch is 180 and 2.3745404169894755 seconds passed\n",
      "Epoch is 190 and 2.5018162501510233 seconds passed\n",
      "Epoch is 200 and 2.6312521670479327 seconds passed\n",
      "Epoch is 210 and 2.757887584157288 seconds passed\n",
      "Epoch is 220 and 2.8905230842065066 seconds passed\n",
      "Epoch is 230 and 3.0191957920324057 seconds passed\n",
      "Epoch is 240 and 3.144961167126894 seconds passed\n",
      "Epoch is 250 and 3.267849792027846 seconds passed\n",
      "Epoch is 260 and 3.3988306671380997 seconds passed\n",
      "Epoch is 270 and 3.5226343751419336 seconds passed\n",
      "Epoch is 280 and 3.662161209154874 seconds passed\n",
      "Epoch is 290 and 3.7940861671231687 seconds passed\n",
      "Epoch is 300 and 3.9273752090521157 seconds passed\n",
      "Epoch is 310 and 4.051928750006482 seconds passed\n",
      "Epoch is 320 and 4.179306667065248 seconds passed\n",
      "Epoch is 330 and 4.310540875187144 seconds passed\n",
      "Epoch is 340 and 4.449860417051241 seconds passed\n",
      "Epoch is 350 and 4.580455125076696 seconds passed\n",
      "Epoch is 360 and 4.716647959081456 seconds passed\n",
      "Epoch is 370 and 4.85360029200092 seconds passed\n",
      "Epoch is 380 and 4.98643833398819 seconds passed\n",
      "Epoch is 390 and 5.115350792184472 seconds passed\n",
      "End of training, took 5.228595667053014 seconds\n",
      "16/16 [==============================] - 0s 372us/step\n",
      "   Bumps  Dirtiness  K_Scatch  Pastry  Stains  Z_Scratch\n",
      "0     61          4         2       5       4          5\n",
      "1      3         79         0       0       0          1\n",
      "2      3          1        73       0       0          3\n",
      "3     15          1         1      56       0          0\n",
      "4      0          0         0       0      80          0\n",
      "5      8          1         2       1       0         73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.75      0.71        81\n",
      "           1       0.92      0.95      0.93        83\n",
      "           2       0.94      0.91      0.92        80\n",
      "           3       0.90      0.77      0.83        73\n",
      "           4       0.95      1.00      0.98        80\n",
      "           5       0.89      0.86      0.87        85\n",
      "\n",
      "    accuracy                           0.88       482\n",
      "   macro avg       0.88      0.87      0.88       482\n",
      "weighted avg       0.88      0.88      0.88       482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history1 = model.fit(X_train1, y_train1, batch_size= 1024, epochs= 1000,  validation_data=(X_val1, y_val1), callbacks=callback,verbose = 0)\n",
    "y_test_pred = model.predict(X_test1)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=-1)\n",
    "\n",
    "cm = confusion_matrix(y_test1, y_test_pred)\n",
    "cm = pd.DataFrame(cm)\n",
    "cm.columns = ['Bumps', 'Dirtiness', 'K_Scatch', 'Pastry', 'Stains', 'Z_Scratch']\n",
    "print(cm)\n",
    "print(classification_report(y_test1, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Epoch is 0 and 0.04342362517490983 seconds passed\n",
      "Epoch is 10 and 0.18152591702528298 seconds passed\n",
      "Epoch is 20 and 0.3223004590254277 seconds passed\n",
      "Epoch is 30 and 0.44597654207609594 seconds passed\n",
      "Epoch is 40 and 0.578534834086895 seconds passed\n",
      "Epoch is 50 and 0.7244151670020074 seconds passed\n",
      "Epoch is 60 and 0.8561744170729071 seconds passed\n",
      "Epoch is 70 and 0.9917370839975774 seconds passed\n",
      "Epoch is 80 and 1.1199831671547145 seconds passed\n",
      "Epoch is 90 and 1.2450727501418442 seconds passed\n",
      "Epoch is 100 and 1.3686686670407653 seconds passed\n",
      "Epoch is 110 and 1.4889258341863751 seconds passed\n",
      "Epoch is 120 and 1.6123568341135979 seconds passed\n",
      "Epoch is 130 and 1.7343207921367139 seconds passed\n",
      "Epoch is 140 and 1.858871917007491 seconds passed\n",
      "Epoch is 150 and 1.983810625039041 seconds passed\n",
      "Epoch is 160 and 2.1102495421655476 seconds passed\n",
      "Epoch is 170 and 2.232792624970898 seconds passed\n",
      "Epoch is 180 and 2.357968709198758 seconds passed\n",
      "Epoch is 190 and 2.483204875141382 seconds passed\n",
      "Epoch is 200 and 2.604989292100072 seconds passed\n",
      "Epoch is 210 and 2.7273633340373635 seconds passed\n",
      "Epoch is 220 and 2.852214709157124 seconds passed\n",
      "Epoch is 230 and 2.973540334030986 seconds passed\n",
      "Epoch is 240 and 3.09620604198426 seconds passed\n",
      "Epoch is 250 and 3.2155088339932263 seconds passed\n",
      "Epoch is 260 and 3.339263000059873 seconds passed\n",
      "Epoch is 270 and 3.463235167087987 seconds passed\n",
      "Epoch is 280 and 3.5829864169936627 seconds passed\n",
      "Epoch is 290 and 3.708407709142193 seconds passed\n",
      "Epoch is 300 and 3.8344786670058966 seconds passed\n",
      "Epoch is 310 and 3.9597932919859886 seconds passed\n",
      "Epoch is 320 and 4.0854490420315415 seconds passed\n",
      "Epoch is 330 and 4.209878167137504 seconds passed\n",
      "Epoch is 340 and 4.3367866249755025 seconds passed\n",
      "Epoch is 350 and 4.470023584086448 seconds passed\n",
      "Epoch is 360 and 4.591675125062466 seconds passed\n",
      "Epoch is 370 and 4.714696042006835 seconds passed\n",
      "Epoch is 380 and 4.836418334161863 seconds passed\n",
      "Epoch is 390 and 4.958171250065789 seconds passed\n",
      "Epoch is 400 and 5.085388000123203 seconds passed\n",
      "Epoch is 410 and 5.209212667075917 seconds passed\n",
      "Epoch is 420 and 5.334142417181283 seconds passed\n",
      "Epoch is 430 and 5.460967333987355 seconds passed\n",
      "Epoch is 440 and 5.585736209060997 seconds passed\n",
      "Epoch is 450 and 5.712935792049393 seconds passed\n",
      "Epoch is 460 and 5.841749292099848 seconds passed\n",
      "Epoch is 470 and 5.967105542076752 seconds passed\n",
      "Epoch is 480 and 6.089174667140469 seconds passed\n",
      "Epoch is 490 and 6.2187299591023475 seconds passed\n",
      "Epoch is 500 and 6.355406334158033 seconds passed\n",
      "Epoch is 510 and 6.4863230001647025 seconds passed\n",
      "Epoch is 520 and 6.6190207921899855 seconds passed\n",
      "Epoch is 530 and 6.751836209092289 seconds passed\n",
      "Epoch is 540 and 6.883094959193841 seconds passed\n",
      "Epoch is 550 and 7.017494749976322 seconds passed\n",
      "Epoch is 560 and 7.142579167149961 seconds passed\n",
      "Epoch is 570 and 7.268540125107393 seconds passed\n",
      "Epoch is 580 and 7.3925717091187835 seconds passed\n",
      "Epoch is 590 and 7.51846554200165 seconds passed\n",
      "Epoch is 600 and 7.6449737921357155 seconds passed\n",
      "Epoch is 610 and 7.7687537090387195 seconds passed\n",
      "End of training, took 7.866602750029415 seconds\n",
      "16/16 [==============================] - 0s 314us/step\n",
      "   Bumps  Dirtiness  K_Scatch  Pastry  Stains  Z_Scratch\n",
      "0      0          4        63       3       6          5\n",
      "1      0         68         8       3       0          4\n",
      "2      0          0        68       3       7          2\n",
      "3      0         27         7      28       0         11\n",
      "4      0          0         0       0      80          0\n",
      "5      0          4        59       6       2         14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        81\n",
      "           1       0.66      0.82      0.73        83\n",
      "           2       0.33      0.85      0.48        80\n",
      "           3       0.65      0.38      0.48        73\n",
      "           4       0.84      1.00      0.91        80\n",
      "           5       0.39      0.16      0.23        85\n",
      "\n",
      "    accuracy                           0.54       482\n",
      "   macro avg       0.48      0.54      0.47       482\n",
      "weighted avg       0.48      0.54      0.47       482\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leetaeryeong/anaconda3/envs/tp1/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/leetaeryeong/anaconda3/envs/tp1/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/leetaeryeong/anaconda3/envs/tp1/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(X_train2, y_train2, batch_size= 1024, epochs= 1000,  validation_data=(X_val2, y_val2), callbacks=callback,verbose = 0)\n",
    "y_test_pred = model.predict(X_test2)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=-1)\n",
    "\n",
    "cm = confusion_matrix(y_test2, y_test_pred)\n",
    "cm = pd.DataFrame(cm)\n",
    "cm.columns = ['Bumps', 'Dirtiness', 'K_Scatch', 'Pastry', 'Stains', 'Z_Scratch']\n",
    "print(cm)\n",
    "print(classification_report(y_test2, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Epoch is 0 and 0.04396874993108213 seconds passed\n",
      "Epoch is 10 and 0.18286520894616842 seconds passed\n",
      "Epoch is 20 and 0.35930870892480016 seconds passed\n",
      "Epoch is 30 and 0.4987312499433756 seconds passed\n",
      "Epoch is 40 and 0.6336792919319123 seconds passed\n",
      "Epoch is 50 and 0.7617287498433143 seconds passed\n",
      "Epoch is 60 and 0.8914465419948101 seconds passed\n",
      "Epoch is 70 and 1.0164580838754773 seconds passed\n",
      "Epoch is 80 and 1.142595374956727 seconds passed\n",
      "Epoch is 90 and 1.2674717500340194 seconds passed\n",
      "Epoch is 100 and 1.3947627919260412 seconds passed\n",
      "Epoch is 110 and 1.5178023339249194 seconds passed\n",
      "Epoch is 120 and 1.6448575840331614 seconds passed\n",
      "Epoch is 130 and 1.7716045000124723 seconds passed\n",
      "Epoch is 140 and 1.900524624856189 seconds passed\n",
      "Epoch is 150 and 2.0255139998625964 seconds passed\n",
      "Epoch is 160 and 2.1507099999580532 seconds passed\n",
      "Epoch is 170 and 2.2758706668391824 seconds passed\n",
      "Epoch is 180 and 2.41073733381927 seconds passed\n",
      "Epoch is 190 and 2.541875666938722 seconds passed\n",
      "Epoch is 200 and 2.6684454998467118 seconds passed\n",
      "Epoch is 210 and 2.7963518749456853 seconds passed\n",
      "Epoch is 220 and 2.92161083384417 seconds passed\n",
      "Epoch is 230 and 3.0464652918744832 seconds passed\n",
      "Epoch is 240 and 3.1715520420111716 seconds passed\n",
      "Epoch is 250 and 3.2955818749032915 seconds passed\n",
      "Epoch is 260 and 3.418664624914527 seconds passed\n",
      "Epoch is 270 and 3.543224041815847 seconds passed\n",
      "Epoch is 280 and 3.6662659170106053 seconds passed\n",
      "Epoch is 290 and 3.7924707918427885 seconds passed\n",
      "Epoch is 300 and 3.9182254169136286 seconds passed\n",
      "Epoch is 310 and 4.041869666893035 seconds passed\n",
      "Epoch is 320 and 4.167217749869451 seconds passed\n",
      "Epoch is 330 and 4.294024375034496 seconds passed\n",
      "Epoch is 340 and 4.427350749960169 seconds passed\n",
      "Epoch is 350 and 4.559913791948929 seconds passed\n",
      "Epoch is 360 and 4.692071708850563 seconds passed\n",
      "Epoch is 370 and 4.822114791953936 seconds passed\n",
      "Epoch is 380 and 4.953683833824471 seconds passed\n",
      "Epoch is 390 and 5.085530333919451 seconds passed\n",
      "Epoch is 400 and 5.2131657500285655 seconds passed\n",
      "Epoch is 410 and 5.337793999817222 seconds passed\n",
      "Epoch is 420 and 5.46878037485294 seconds passed\n",
      "Epoch is 430 and 5.589980124961585 seconds passed\n",
      "Epoch is 440 and 5.716820458881557 seconds passed\n",
      "Epoch is 450 and 5.839306833921 seconds passed\n",
      "Epoch is 460 and 5.96277662483044 seconds passed\n",
      "Epoch is 470 and 6.092090124962851 seconds passed\n",
      "Epoch is 480 and 6.22454870888032 seconds passed\n",
      "Epoch is 490 and 6.348214916884899 seconds passed\n",
      "Epoch is 500 and 6.472002291819081 seconds passed\n",
      "Epoch is 510 and 6.598951958818361 seconds passed\n",
      "Epoch is 520 and 6.731265709036961 seconds passed\n",
      "Epoch is 530 and 6.868243959033862 seconds passed\n",
      "Epoch is 540 and 6.997271375032142 seconds passed\n",
      "Epoch is 550 and 7.13236404187046 seconds passed\n",
      "Epoch is 560 and 7.262263541808352 seconds passed\n",
      "Epoch is 570 and 7.3976284170057625 seconds passed\n",
      "Epoch is 580 and 7.5231663750018924 seconds passed\n",
      "Epoch is 590 and 7.64876020886004 seconds passed\n",
      "Epoch is 600 and 7.779167583910748 seconds passed\n",
      "End of training, took 7.835400374839082 seconds\n",
      "16/16 [==============================] - 0s 342us/step\n",
      "   Bumps  Dirtiness  K_Scatch  Pastry  Stains  Z_Scratch\n",
      "0     55          4         1      16       2          3\n",
      "1      0         78         0       4       0          1\n",
      "2      6          0        72       0       1          1\n",
      "3     23          9         1      39       0          1\n",
      "4      0          0         0       0      80          0\n",
      "5     11          1         3       0       0         70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.68      0.63        81\n",
      "           1       0.85      0.94      0.89        83\n",
      "           2       0.94      0.90      0.92        80\n",
      "           3       0.66      0.53      0.59        73\n",
      "           4       0.96      1.00      0.98        80\n",
      "           5       0.92      0.82      0.87        85\n",
      "\n",
      "    accuracy                           0.82       482\n",
      "   macro avg       0.82      0.81      0.81       482\n",
      "weighted avg       0.82      0.82      0.82       482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history01 = model.fit(X_train3, y_train3, batch_size= 1024, epochs= 1000,  validation_data=(X_val3, y_val3), callbacks=callback,verbose = 0)\n",
    "y_test_pred = model.predict(X_test3)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=-1)\n",
    "\n",
    "cm = confusion_matrix(y_test3, y_test_pred)\n",
    "cm = pd.DataFrame(cm)\n",
    "cm.columns = ['Bumps', 'Dirtiness', 'K_Scatch', 'Pastry', 'Stains', 'Z_Scratch']\n",
    "print(cm)\n",
    "print(classification_report(y_test3, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Epoch is 0 and 0.04378641699440777 seconds passed\n",
      "Epoch is 10 and 0.1762625421397388 seconds passed\n",
      "Epoch is 20 and 0.3028554581105709 seconds passed\n",
      "Epoch is 30 and 0.4243157079908997 seconds passed\n",
      "Epoch is 40 and 0.5494802920147777 seconds passed\n",
      "Epoch is 50 and 0.6718676669988781 seconds passed\n",
      "Epoch is 60 and 0.7982687500771135 seconds passed\n",
      "Epoch is 70 and 0.9231084580533206 seconds passed\n",
      "Epoch is 80 and 1.050830125110224 seconds passed\n",
      "Epoch is 90 and 1.18641662504524 seconds passed\n",
      "Epoch is 100 and 1.3125228330027312 seconds passed\n",
      "Epoch is 110 and 1.4458203751128167 seconds passed\n",
      "Epoch is 120 and 1.5760630001313984 seconds passed\n",
      "Epoch is 130 and 1.6996437080670148 seconds passed\n",
      "Epoch is 140 and 1.8235830829944462 seconds passed\n",
      "Epoch is 150 and 1.9479388750623912 seconds passed\n",
      "Epoch is 160 and 2.0739214171189815 seconds passed\n",
      "Epoch is 170 and 2.1982439579442143 seconds passed\n",
      "Epoch is 180 and 2.322323667118326 seconds passed\n",
      "Epoch is 190 and 2.443772708065808 seconds passed\n",
      "Epoch is 200 and 2.5670556670520455 seconds passed\n",
      "Epoch is 210 and 2.6886172499507666 seconds passed\n",
      "Epoch is 220 and 2.8115737079642713 seconds passed\n",
      "Epoch is 230 and 2.9329104169737548 seconds passed\n",
      "Epoch is 240 and 3.0533799580298364 seconds passed\n",
      "Epoch is 250 and 3.182844042079523 seconds passed\n",
      "Epoch is 260 and 3.3062816669698805 seconds passed\n",
      "Epoch is 270 and 3.4263473751489073 seconds passed\n",
      "Epoch is 280 and 3.5506359580904245 seconds passed\n",
      "Epoch is 290 and 3.6738161251414567 seconds passed\n",
      "Epoch is 300 and 3.7964032921008766 seconds passed\n",
      "Epoch is 310 and 3.9202816251199692 seconds passed\n",
      "Epoch is 320 and 4.0518042501062155 seconds passed\n",
      "Epoch is 330 and 4.177440708037466 seconds passed\n",
      "Epoch is 340 and 4.310431082965806 seconds passed\n",
      "Epoch is 350 and 4.4330564581323415 seconds passed\n",
      "Epoch is 360 and 4.558683082927018 seconds passed\n",
      "Epoch is 370 and 4.6819245419465005 seconds passed\n",
      "Epoch is 380 and 4.805459458148107 seconds passed\n",
      "Epoch is 390 and 4.926595625001937 seconds passed\n",
      "Epoch is 400 and 5.047631582943723 seconds passed\n",
      "Epoch is 410 and 5.168833249947056 seconds passed\n",
      "Epoch is 420 and 5.293534625088796 seconds passed\n",
      "Epoch is 430 and 5.415961000137031 seconds passed\n",
      "Epoch is 440 and 5.543863292085007 seconds passed\n",
      "Epoch is 450 and 5.6715396251529455 seconds passed\n",
      "Epoch is 460 and 5.8049134579487145 seconds passed\n",
      "Epoch is 470 and 5.9347017500549555 seconds passed\n",
      "Epoch is 480 and 6.06719741714187 seconds passed\n",
      "Epoch is 490 and 6.194512916961685 seconds passed\n",
      "Epoch is 500 and 6.321038417052478 seconds passed\n",
      "Epoch is 510 and 6.450419125147164 seconds passed\n",
      "Epoch is 520 and 6.580642082961276 seconds passed\n",
      "Epoch is 530 and 6.71634970814921 seconds passed\n",
      "Epoch is 540 and 6.860308500006795 seconds passed\n",
      "Epoch is 550 and 6.99645825009793 seconds passed\n",
      "Epoch is 560 and 7.128838625038043 seconds passed\n",
      "Epoch is 570 and 7.261481208028272 seconds passed\n",
      "Epoch is 580 and 7.389621250098571 seconds passed\n",
      "Epoch is 590 and 7.513935707975179 seconds passed\n",
      "Epoch is 600 and 7.638977749971673 seconds passed\n",
      "Epoch is 610 and 7.77709429198876 seconds passed\n",
      "Epoch is 620 and 7.901976250112057 seconds passed\n",
      "Epoch is 630 and 8.03315187501721 seconds passed\n",
      "Epoch is 640 and 8.16100712493062 seconds passed\n",
      "Epoch is 650 and 8.29252720810473 seconds passed\n",
      "Epoch is 660 and 8.418558125151321 seconds passed\n",
      "Epoch is 670 and 8.544398500118405 seconds passed\n",
      "Epoch is 680 and 8.67705687507987 seconds passed\n",
      "Epoch is 690 and 8.804505625041202 seconds passed\n",
      "End of training, took 8.819975499995053 seconds\n",
      "16/16 [==============================] - 0s 298us/step\n",
      "   Bumps  Dirtiness  K_Scatch  Pastry  Stains  Z_Scratch\n",
      "0     21          5         6       9      20         20\n",
      "1      5         16         4       1      48          9\n",
      "2      1          0        54       4      21          0\n",
      "3     22          4        14       9      11         13\n",
      "4      0          9         0       0      71          0\n",
      "5      8         12         6       1      43         15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.26      0.30        81\n",
      "           1       0.35      0.19      0.25        83\n",
      "           2       0.64      0.68      0.66        80\n",
      "           3       0.38      0.12      0.19        73\n",
      "           4       0.33      0.89      0.48        80\n",
      "           5       0.26      0.18      0.21        85\n",
      "\n",
      "    accuracy                           0.39       482\n",
      "   macro avg       0.39      0.39      0.35       482\n",
      "weighted avg       0.39      0.39      0.35       482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history01 = model.fit(X_train4, y_train4, batch_size= 1024, epochs= 1000,  validation_data=(X_val4, y_val4), callbacks=callback,verbose = 0)\n",
    "y_test_pred = model.predict(X_test4)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=-1)\n",
    "\n",
    "cm = confusion_matrix(y_test4, y_test_pred)\n",
    "cm = pd.DataFrame(cm)\n",
    "cm.columns = ['Bumps', 'Dirtiness', 'K_Scatch', 'Pastry', 'Stains', 'Z_Scratch']\n",
    "print(cm)\n",
    "print(classification_report(y_test4, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
